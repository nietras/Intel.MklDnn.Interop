// ----------------------------------------------------------------------------
// <auto-generated>
// This is autogenerated code by CppSharp.
// Do not edit this file or all your changes will be lost after re-generation.
// </auto-generated>
// ----------------------------------------------------------------------------
using System;
using System.Runtime.InteropServices;
using System.Security;

namespace Intel.MklDnn
{
    public unsafe partial class mkldnn
    {
        public partial struct __Internal
        {
            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_iterator_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescIteratorCreate(global::System.IntPtr iterator, global::System.IntPtr op_desc, global::System.IntPtr attr, global::System.IntPtr engine, global::System.IntPtr hint_forward_primitive_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_iterator_next")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescIteratorNext(global::System.IntPtr iterator);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_iterator_fetch")]
            internal static extern global::System.IntPtr MkldnnPrimitiveDescIteratorFetch(global::System.IntPtr iterator);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_iterator_destroy")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescIteratorDestroy(global::System.IntPtr iterator);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescCreate(global::System.IntPtr primitive_desc, global::System.IntPtr op_desc, global::System.IntPtr attr, global::System.IntPtr engine, global::System.IntPtr hint_forward_primitive_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_clone")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescClone(global::System.IntPtr primitive_desc, global::System.IntPtr existing_primitive_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_get_attr")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescGetAttr(global::System.IntPtr primitive_desc, global::System.IntPtr attr);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_destroy")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescDestroy(global::System.IntPtr primitive_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_query")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescQuery(global::System.IntPtr primitive_desc, global::Intel.MklDnn.MkldnnQueryT what, int index, global::System.IntPtr result);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_query_md")]
            internal static extern global::System.IntPtr MkldnnPrimitiveDescQueryMd(global::System.IntPtr primitive_desc, global::Intel.MklDnn.MkldnnQueryT what, int index);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_desc_query_s32")]
            internal static extern int MkldnnPrimitiveDescQueryS32(global::System.IntPtr primitive_desc, global::Intel.MklDnn.MkldnnQueryT what, int index);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveCreate(global::System.IntPtr primitive, global::System.IntPtr primitive_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_execute")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveExecute(global::System.IntPtr primitive, global::System.IntPtr stream, int nargs, global::System.IntPtr args);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_get_primitive_desc")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveGetPrimitiveDesc(global::System.IntPtr primitive, global::System.IntPtr primitive_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_destroy")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDestroy(global::System.IntPtr primitive);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrCreate(global::System.IntPtr attr);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_clone")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrClone(global::System.IntPtr attr, global::System.IntPtr existing_attr);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_destroy")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrDestroy(global::System.IntPtr attr);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_get_scratchpad_mode")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrGetScratchpadMode(global::System.IntPtr attr, global::Intel.MklDnn.MkldnnScratchpadModeT* mode);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_set_scratchpad_mode")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetScratchpadMode(global::System.IntPtr attr, global::Intel.MklDnn.MkldnnScratchpadModeT mode);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_get_output_scales")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrGetOutputScales(global::System.IntPtr attr, long* count, int* mask, float** scales);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_set_output_scales")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetOutputScales(global::System.IntPtr attr, long count, int mask, float* scales);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_get_post_ops")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrGetPostOps(global::System.IntPtr attr, global::System.IntPtr post_ops);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_set_post_ops")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetPostOps(global::System.IntPtr attr, global::System.IntPtr post_ops);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_post_ops_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsCreate(global::System.IntPtr post_ops);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_post_ops_destroy")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsDestroy(global::System.IntPtr post_ops);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_post_ops_len")]
            internal static extern int MkldnnPostOpsLen(global::System.IntPtr post_ops);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_post_ops_get_kind")]
            internal static extern global::Intel.MklDnn.MkldnnPrimitiveKindT MkldnnPostOpsGetKind(global::System.IntPtr post_ops, int index);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_post_ops_append_sum")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsAppendSum(global::System.IntPtr post_ops, float scale);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_post_ops_get_params_sum")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsGetParamsSum(global::System.IntPtr post_ops, int index, float* scale);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_post_ops_append_eltwise")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsAppendEltwise(global::System.IntPtr post_ops, float scale, global::Intel.MklDnn.MkldnnAlgKindT alg, float alpha, float beta);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_post_ops_get_params_eltwise")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsGetParamsEltwise(global::System.IntPtr post_ops, int index, float* scale, global::Intel.MklDnn.MkldnnAlgKindT* alg, float* alpha, float* beta);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_desc_init_by_strides")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryDescInitByStrides(global::System.IntPtr memory_desc, int ndims, long[] dims, global::Intel.MklDnn.MkldnnDataTypeT data_type, long[] strides);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_desc_init_by_tag")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryDescInitByTag(global::System.IntPtr memory_desc, int ndims, long[] dims, global::Intel.MklDnn.MkldnnDataTypeT data_type, global::Intel.MklDnn.MkldnnFormatTagT tag);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_desc_init_submemory")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryDescInitSubmemory(global::System.IntPtr memory_desc, global::System.IntPtr parent_memory_desc, long[] dims, long[] offsets);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_desc_equal")]
            internal static extern int MkldnnMemoryDescEqual(global::System.IntPtr lhs, global::System.IntPtr rhs);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_desc_get_size")]
            internal static extern ulong MkldnnMemoryDescGetSize(global::System.IntPtr memory_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryCreate(global::System.IntPtr memory, global::System.IntPtr memory_desc, global::System.IntPtr engine, global::System.IntPtr handle);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_get_memory_desc")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryGetMemoryDesc(global::System.IntPtr memory, global::System.IntPtr memory_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_get_engine")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryGetEngine(global::System.IntPtr memory, global::System.IntPtr engine);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_map_data")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryMapData(global::System.IntPtr memory, void** mapped_ptr);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_unmap_data")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryUnmapData(global::System.IntPtr memory, global::System.IntPtr mapped_ptr);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_get_data_handle")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryGetDataHandle(global::System.IntPtr memory, void** handle);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_set_data_handle")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemorySetDataHandle(global::System.IntPtr memory, global::System.IntPtr handle);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_memory_destroy")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryDestroy(global::System.IntPtr memory);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_reorder_primitive_desc_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnReorderPrimitiveDescCreate(global::System.IntPtr reorder_primitive_desc, global::System.IntPtr src_md, global::System.IntPtr src_engine, global::System.IntPtr dst_md, global::System.IntPtr dst_engine, global::System.IntPtr attr);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_concat_primitive_desc_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnConcatPrimitiveDescCreate(global::System.IntPtr concat_primitive_desc, global::System.IntPtr dst_md, int n, int concat_dimension, global::System.IntPtr src_mds, global::System.IntPtr attr, global::System.IntPtr engine);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_sum_primitive_desc_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnSumPrimitiveDescCreate(global::System.IntPtr sum_primitive_desc, global::System.IntPtr dst_mds, int n, float* scales, global::System.IntPtr src_mds, global::System.IntPtr attr, global::System.IntPtr engine);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_convolution_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnConvolutionForwardDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr weights_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_desc, long[] strides, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_dilated_convolution_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedConvolutionForwardDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr weights_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_convolution_backward_data_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnConvolutionBackwardDataDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr diff_src_desc, global::System.IntPtr weights_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_dilated_convolution_backward_data_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedConvolutionBackwardDataDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr diff_src_desc, global::System.IntPtr weights_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_convolution_backward_weights_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnConvolutionBackwardWeightsDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr diff_weights_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_dilated_convolution_backward_weights_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedConvolutionBackwardWeightsDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr diff_weights_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_deconvolution_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDeconvolutionForwardDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr weights_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_desc, long[] strides, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_dilated_deconvolution_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedDeconvolutionForwardDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr weights_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_deconvolution_backward_data_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDeconvolutionBackwardDataDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr diff_src_desc, global::System.IntPtr weights_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_dilated_deconvolution_backward_data_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedDeconvolutionBackwardDataDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr diff_src_desc, global::System.IntPtr weights_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_deconvolution_backward_weights_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDeconvolutionBackwardWeightsDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr diff_weights_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_dilated_deconvolution_backward_weights_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedDeconvolutionBackwardWeightsDescInit(global::System.IntPtr conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr diff_weights_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_shuffle_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnShuffleForwardDescInit(global::System.IntPtr shuffle_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::System.IntPtr data_desc, int axis, long group_size);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_shuffle_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnShuffleBackwardDescInit(global::System.IntPtr shuffle_desc, global::System.IntPtr diff_data_desc, int axis, long group_size);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_eltwise_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnEltwiseForwardDescInit(global::System.IntPtr eltwise_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr data_desc, float alpha, float beta);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_eltwise_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnEltwiseBackwardDescInit(global::System.IntPtr eltwise_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr diff_data_desc, global::System.IntPtr data_desc, float alpha, float beta);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_softmax_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnSoftmaxForwardDescInit(global::System.IntPtr softmax_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::System.IntPtr data_desc, int softmax_axis);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_softmax_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnSoftmaxBackwardDescInit(global::System.IntPtr softmax_desc, global::System.IntPtr diff_desc, global::System.IntPtr data_desc, int softmax_axis);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_pooling_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPoolingForwardDescInit(global::System.IntPtr pool_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr src_desc, global::System.IntPtr dst_desc, long[] strides, long[] kernel, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_pooling_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPoolingBackwardDescInit(global::System.IntPtr pool_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr diff_src_desc, global::System.IntPtr diff_dst_desc, long[] strides, long[] kernel, long[] padding_l, long[] padding_r);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_lrn_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnLrnForwardDescInit(global::System.IntPtr lrn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr data_desc, long local_size, float alpha, float beta, float k);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_lrn_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnLrnBackwardDescInit(global::System.IntPtr lrn_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::System.IntPtr diff_data_desc, global::System.IntPtr data_desc, long local_size, float alpha, float beta, float k);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_batch_normalization_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnBatchNormalizationForwardDescInit(global::System.IntPtr bnrm_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::System.IntPtr data_desc, float epsilon, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_batch_normalization_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnBatchNormalizationBackwardDescInit(global::System.IntPtr bnrm_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::System.IntPtr diff_data_desc, global::System.IntPtr data_desc, float epsilon, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_inner_product_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnInnerProductForwardDescInit(global::System.IntPtr ip_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::System.IntPtr src_desc, global::System.IntPtr weights_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_inner_product_backward_data_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnInnerProductBackwardDataDescInit(global::System.IntPtr ip_desc, global::System.IntPtr diff_src_desc, global::System.IntPtr weights_desc, global::System.IntPtr diff_dst_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_inner_product_backward_weights_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnInnerProductBackwardWeightsDescInit(global::System.IntPtr ip_desc, global::System.IntPtr src_desc, global::System.IntPtr diff_weights_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_desc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_set_rnn_data_qparams")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetRnnDataQparams(global::System.IntPtr attr, float scale, float shift);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_primitive_attr_set_rnn_weights_qparams")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetRnnWeightsQparams(global::System.IntPtr attr, long count, int mask, float* weights_scales);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_vanilla_rnn_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnVanillaRnnForwardDescInit(global::System.IntPtr rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT activation, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::System.IntPtr src_layer_desc, global::System.IntPtr src_iter_desc, global::System.IntPtr weights_layer_desc, global::System.IntPtr weights_iter_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_layer_desc, global::System.IntPtr dst_iter_desc, uint flags, float alpha, float beta);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_vanilla_rnn_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnVanillaRnnBackwardDescInit(global::System.IntPtr rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT activation, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::System.IntPtr src_layer_desc, global::System.IntPtr src_iter_desc, global::System.IntPtr weights_layer_desc, global::System.IntPtr weights_iter_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_layer_desc, global::System.IntPtr dst_iter_desc, global::System.IntPtr diff_src_layer_desc, global::System.IntPtr diff_src_iter_desc, global::System.IntPtr diff_weights_layer_desc, global::System.IntPtr diff_weights_iter_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_layer_desc, global::System.IntPtr diff_dst_iter_desc, uint flags, float alpha, float beta);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_lstm_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnLstmForwardDescInit(global::System.IntPtr rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::System.IntPtr src_layer_desc, global::System.IntPtr src_iter_desc, global::System.IntPtr src_iter_c_desc, global::System.IntPtr weights_layer_desc, global::System.IntPtr weights_iter_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_layer_desc, global::System.IntPtr dst_iter_desc, global::System.IntPtr dst_iter_c_desc, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_lstm_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnLstmBackwardDescInit(global::System.IntPtr rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::System.IntPtr src_layer_desc, global::System.IntPtr src_iter_desc, global::System.IntPtr src_iter_c_desc, global::System.IntPtr weights_layer_desc, global::System.IntPtr weights_iter_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_layer_desc, global::System.IntPtr dst_iter_desc, global::System.IntPtr dst_iter_c_desc, global::System.IntPtr diff_src_layer_desc, global::System.IntPtr diff_src_iter_desc, global::System.IntPtr diff_src_iter_c_desc, global::System.IntPtr diff_weights_layer_desc, global::System.IntPtr diff_weights_iter_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_layer_desc, global::System.IntPtr diff_dst_iter_desc, global::System.IntPtr diff_dst_iter_c_desc, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_gru_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnGruForwardDescInit(global::System.IntPtr rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::System.IntPtr src_layer_desc, global::System.IntPtr src_iter_desc, global::System.IntPtr weights_layer_desc, global::System.IntPtr weights_iter_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_layer_desc, global::System.IntPtr dst_iter_desc, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_gru_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnGruBackwardDescInit(global::System.IntPtr rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::System.IntPtr src_layer_desc, global::System.IntPtr src_iter_desc, global::System.IntPtr weights_layer_desc, global::System.IntPtr weights_iter_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_layer_desc, global::System.IntPtr dst_iter_desc, global::System.IntPtr diff_src_layer_desc, global::System.IntPtr diff_src_iter_desc, global::System.IntPtr diff_weights_layer_desc, global::System.IntPtr diff_weights_iter_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_layer_desc, global::System.IntPtr diff_dst_iter_desc, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_lbr_gru_forward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnLbrGruForwardDescInit(global::System.IntPtr rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::System.IntPtr src_layer_desc, global::System.IntPtr src_iter_desc, global::System.IntPtr weights_layer_desc, global::System.IntPtr weights_iter_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_layer_desc, global::System.IntPtr dst_iter_desc, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_lbr_gru_backward_desc_init")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnLbrGruBackwardDescInit(global::System.IntPtr rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::System.IntPtr src_layer_desc, global::System.IntPtr src_iter_desc, global::System.IntPtr weights_layer_desc, global::System.IntPtr weights_iter_desc, global::System.IntPtr bias_desc, global::System.IntPtr dst_layer_desc, global::System.IntPtr dst_iter_desc, global::System.IntPtr diff_src_layer_desc, global::System.IntPtr diff_src_iter_desc, global::System.IntPtr diff_weights_layer_desc, global::System.IntPtr diff_weights_iter_desc, global::System.IntPtr diff_bias_desc, global::System.IntPtr diff_dst_layer_desc, global::System.IntPtr diff_dst_iter_desc, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_engine_get_count")]
            internal static extern ulong MkldnnEngineGetCount(global::Intel.MklDnn.MkldnnEngineKindT kind);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_engine_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnEngineCreate(global::System.IntPtr engine, global::Intel.MklDnn.MkldnnEngineKindT kind, ulong index);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_engine_get_kind")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnEngineGetKind(global::System.IntPtr engine, global::Intel.MklDnn.MkldnnEngineKindT* kind);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_engine_destroy")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnEngineDestroy(global::System.IntPtr engine);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_stream_create")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnStreamCreate(global::System.IntPtr stream, global::System.IntPtr engine, uint flags);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_stream_wait")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnStreamWait(global::System.IntPtr stream);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_stream_destroy")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnStreamDestroy(global::System.IntPtr stream);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_set_verbose")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnSetVerbose(int level);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_set_jit_dump")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnSetJitDump(int enable);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_version")]
            internal static extern global::System.IntPtr MkldnnVersion();

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_sgemm")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnSgemm(sbyte transa, sbyte transb, long M, long N, long K, float alpha, float* A, long lda, float* B, long ldb, float beta, float* C, long ldc);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_gemm_u8s8s32")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnGemmU8s8s32(sbyte transa, sbyte transb, sbyte offsetc, long M, long N, long K, float alpha, byte* A, long lda, byte ao, sbyte* B, long ldb, sbyte bo, float beta, int* C, long ldc, int* co);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_gemm_s8s8s32")]
            internal static extern global::Intel.MklDnn.MkldnnStatusT MkldnnGemmS8s8s32(sbyte transa, sbyte transb, sbyte offsetc, long M, long N, long K, float alpha, sbyte* A, long lda, sbyte ao, sbyte* B, long ldb, sbyte bo, float beta, int* C, long ldc, int* co);
        }

        /// <summary>
/// <para>Creates a primitive descriptorfor givenand optionally a hint primitive descriptor from forward</para>
/// <para>propagation (required for backward propagation). Passfor forward</para>
/// <para>propagation.</para>
/// </summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescIteratorCreate(global::Intel.MklDnn.MkldnnPrimitiveDescIterator iterator, global::System.IntPtr op_desc, global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnEngine engine, global::Intel.MklDnn.MkldnnPrimitiveDesc hint_forward_primitive_desc)
        {
            var ____arg0 = ReferenceEquals(iterator, null) ? global::System.IntPtr.Zero : iterator.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg2 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __arg3 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __arg4 = ReferenceEquals(hint_forward_primitive_desc, null) ? global::System.IntPtr.Zero : hint_forward_primitive_desc.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescIteratorCreate(__arg0, op_desc, __arg2, __arg3, __arg4);
            return __ret;
        }

        /// <summary>
/// <para>Iterates over primitive descriptors. Returns #mkldnn_iterator_ends if no</para>
/// <para>more primitive descriptors are available.</para>
/// </summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescIteratorNext(global::Intel.MklDnn.MkldnnPrimitiveDescIterator iterator)
        {
            var __arg0 = ReferenceEquals(iterator, null) ? global::System.IntPtr.Zero : iterator.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescIteratorNext(__arg0);
            return __ret;
        }

        /// <summary>Fetches the current primitive descriptor.</summary>
/// <remarks>
/// <para>The user should delete the fetched primitive descriptor using</para>
/// <para>mkldnn_primitive_desc_destroy() once it is no longer needed.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnPrimitiveDesc MkldnnPrimitiveDescIteratorFetch(global::Intel.MklDnn.MkldnnPrimitiveDescIterator iterator)
        {
            var __arg0 = ReferenceEquals(iterator, null) ? global::System.IntPtr.Zero : iterator.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescIteratorFetch(__arg0);
            global::Intel.MklDnn.MkldnnPrimitiveDesc __result0;
            if (__ret == IntPtr.Zero) __result0 = null;
            else if (global::Intel.MklDnn.MkldnnPrimitiveDesc.NativeToManagedMap.ContainsKey(__ret))
                __result0 = (global::Intel.MklDnn.MkldnnPrimitiveDesc) global::Intel.MklDnn.MkldnnPrimitiveDesc.NativeToManagedMap[__ret];
            else __result0 = global::Intel.MklDnn.MkldnnPrimitiveDesc.__CreateInstance(__ret);
            return __result0;
        }

        /// <summary>Deletes a primitive descriptor</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescIteratorDestroy(global::Intel.MklDnn.MkldnnPrimitiveDescIterator iterator)
        {
            var __arg0 = ReferenceEquals(iterator, null) ? global::System.IntPtr.Zero : iterator.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescIteratorDestroy(__arg0);
            return __ret;
        }

        /// <summary>
/// <para>Creates ausingand</para>
/// <para>optionally a hint primitive descriptor from forward propagation. The call is</para>
/// <para>equivalent to creating a primitive descriptor iterator, immediately fetching</para>
/// <para>a primitive descriptor, and then destroying the iterator.</para>
/// </summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescCreate(global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc, global::System.IntPtr op_desc, global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnEngine engine, global::Intel.MklDnn.MkldnnPrimitiveDesc hint_forward_primitive_desc)
        {
            var ____arg0 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg2 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __arg3 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __arg4 = ReferenceEquals(hint_forward_primitive_desc, null) ? global::System.IntPtr.Zero : hint_forward_primitive_desc.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescCreate(__arg0, op_desc, __arg2, __arg3, __arg4);
            return __ret;
        }

        /// <summary>Makes a copy of a</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescClone(global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc, global::Intel.MklDnn.MkldnnPrimitiveDesc existing_primitive_desc)
        {
            var ____arg0 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg1 = ReferenceEquals(existing_primitive_desc, null) ? global::System.IntPtr.Zero : existing_primitive_desc.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescClone(__arg0, __arg1);
            return __ret;
        }

        /// <summary>Returns a constant reference to the attribute of a</summary>
/// <remarks>
/// <para>The user should not destroy the obtained</para>
/// <para>The lifetime of anis the same as that of aso it is illegal to use theoncehas been</para>
/// <para>destroyed.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescGetAttr(global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc, global::Intel.MklDnn.MkldnnPrimitiveAttr attr)
        {
            var __arg0 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var ____arg1 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __arg1 = new global::System.IntPtr(&____arg1);
            var __ret = __Internal.MkldnnPrimitiveDescGetAttr(__arg0, __arg1);
            return __ret;
        }

        /// <summary>Deletes a</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescDestroy(global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc)
        {
            var __arg0 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescDestroy(__arg0);
            return __ret;
        }

        /// <summary>Queries primitive descriptor</summary>
/// <remarks>
/// <para>One of the most typical use cases is to query a primitive descriptor</para>
/// <para>created with source, weights, and destination formats equal</para>
/// <para>to #mkldnn_format_tag_any about the corresponding memory descriptors</para>
/// <para>(equals #mkldnn_query_src_md, #mkldnn_query_weights_md, and</para>
/// <para>#mkldnn_query_dst_md respectively) to be able to prepare memory and</para>
/// <para>create reorders if required.</para>
/// <para>Another quite typical use case is to query an operation primitive</para>
/// <para>descriptor for a workspace (equals #mkldnn_query_workspace_md).</para>
/// <para>The returned status #mkldnn_not_required indicates that a workspace is</para>
/// <para>not required.</para>
/// <para>When querying a memory descriptor for a scratchpad, a</para>
/// <para>workspace, or an optional parameter, the query will return a</para>
/// <para>zero_md if the parameter is not needed.</para>
/// <para>A few other possibilities:</para>
/// <para>- query an operation primitive descriptor for the underlying operation</para>
/// <para>descriptor (#mkldnn_query_convolution_d, #mkldnn_query_eltwise_d,</para>
/// <para>#mkldnn_query_rnn_d, etc.)</para>
/// <para>- query an operation primitive descriptor for the implementation</para>
/// <para>information string (#mkldnn_query_impl_info_str)</para>
/// <para>- query an operation primitive descriptor for the number of inputs and</para>
/// <para>outputs (#mkldnn_query_num_of_inputs_s32 and</para>
/// <para>#mkldnn_query_num_of_outputs_s32 respectively)</para>
/// <para>mkldnn_query_t for more options</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDescQuery(global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc, global::Intel.MklDnn.MkldnnQueryT what, int index, global::System.IntPtr result)
        {
            var __arg0 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescQuery(__arg0, what, index, result);
            return __ret;
        }

        /// <summary>Queries primitive descriptor for memory descriptor</summary>
/// <remarks>
/// <para>NULL in case of any error.</para>
/// <para>This is just a specialized version of mkldnn_primitive_desc_query</para>
/// <para>used for convenience.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnMemoryDescT MkldnnPrimitiveDescQueryMd(global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc, global::Intel.MklDnn.MkldnnQueryT what, int index)
        {
            var __arg0 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescQueryMd(__arg0, what, index);
            global::Intel.MklDnn.MkldnnMemoryDescT __result0;
            if (__ret == IntPtr.Zero) __result0 = null;
            else if (global::Intel.MklDnn.MkldnnMemoryDescT.NativeToManagedMap.ContainsKey(__ret))
                __result0 = (global::Intel.MklDnn.MkldnnMemoryDescT) global::Intel.MklDnn.MkldnnMemoryDescT.NativeToManagedMap[__ret];
            else __result0 = global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(__ret);
            return __result0;
        }

        /// <summary>Queries primitive descriptor for signed 32bit int</summary>
/// <remarks>
/// <para>0 in case of any error (in particular if the queried entity is</para>
/// <para>not of type int32_t). Note that 0 might also be the actual returned</para>
/// <para>value.</para>
/// <para>This is just a specialized version of mkldnn_primitive_desc_query</para>
/// <para>used for convenience.</para>
/// </remarks>
        public static int MkldnnPrimitiveDescQueryS32(global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc, global::Intel.MklDnn.MkldnnQueryT what, int index)
        {
            var __arg0 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDescQueryS32(__arg0, what, index);
            return __ret;
        }

        /// <summary>Creates ausing adescriptor.</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveCreate(global::Intel.MklDnn.MkldnnPrimitive primitive, global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc)
        {
            var ____arg0 = ReferenceEquals(primitive, null) ? global::System.IntPtr.Zero : primitive.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg1 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var __ret = __Internal.MkldnnPrimitiveCreate(__arg0, __arg1);
            return __ret;
        }

        /// <summary>Executes ausing aandarguments</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveExecute(global::Intel.MklDnn.MkldnnPrimitive primitive, global::Intel.MklDnn.MkldnnStream stream, int nargs, global::Intel.MklDnn.MkldnnExecArgT args)
        {
            var __arg0 = ReferenceEquals(primitive, null) ? global::System.IntPtr.Zero : primitive.__Instance;
            var __arg1 = ReferenceEquals(stream, null) ? global::System.IntPtr.Zero : stream.__Instance;
            var __arg3 = ReferenceEquals(args, null) ? global::System.IntPtr.Zero : args.__Instance;
            var __ret = __Internal.MkldnnPrimitiveExecute(__arg0, __arg1, nargs, __arg3);
            return __ret;
        }

        /// <summary>Retrieves a reference to thedescriptor of given</summary>
/// <remarks>The returned object must not be destroyed by the user. Thequalifier of the returned object prevents such attempts.</remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveGetPrimitiveDesc(global::Intel.MklDnn.MkldnnPrimitive primitive, global::Intel.MklDnn.MkldnnPrimitiveDesc primitive_desc)
        {
            var __arg0 = ReferenceEquals(primitive, null) ? global::System.IntPtr.Zero : primitive.__Instance;
            var ____arg1 = ReferenceEquals(primitive_desc, null) ? global::System.IntPtr.Zero : primitive_desc.__Instance;
            var __arg1 = new global::System.IntPtr(&____arg1);
            var __ret = __Internal.MkldnnPrimitiveGetPrimitiveDesc(__arg0, __arg1);
            return __ret;
        }

        /// <summary>Deletes a</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveDestroy(global::Intel.MklDnn.MkldnnPrimitive primitive)
        {
            var __arg0 = ReferenceEquals(primitive, null) ? global::System.IntPtr.Zero : primitive.__Instance;
            var __ret = __Internal.MkldnnPrimitiveDestroy(__arg0);
            return __ret;
        }

        /// <summary>
/// <para>Creates an empty (default)attribute. All the parameters are set to</para>
/// <para>default values.</para>
/// </summary>
/// <remarks>
/// <para>An empty attribute is used in primitive descriptor creation whenever it</para>
/// <para>is not passed explicitly, e.g. in mkldnn_primitive_desc_create.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrCreate(global::Intel.MklDnn.MkldnnPrimitiveAttr attr)
        {
            var ____arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __ret = __Internal.MkldnnPrimitiveAttrCreate(__arg0);
            return __ret;
        }

        /// <summary>Makes a copy of an</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrClone(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnPrimitiveAttr existing_attr)
        {
            var ____arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg1 = ReferenceEquals(existing_attr, null) ? global::System.IntPtr.Zero : existing_attr.__Instance;
            var __ret = __Internal.MkldnnPrimitiveAttrClone(__arg0, __arg1);
            return __ret;
        }

        /// <summary>Deletes an</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrDestroy(global::Intel.MklDnn.MkldnnPrimitiveAttr attr)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __ret = __Internal.MkldnnPrimitiveAttrDestroy(__arg0);
            return __ret;
        }

        /// <summary>Returns the scratchpadset in the attribute</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrGetScratchpadMode(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnScratchpadModeT* mode)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __ret = __Internal.MkldnnPrimitiveAttrGetScratchpadMode(__arg0, mode);
            return __ret;
        }

        /// <summary>Sets scratchpad</summary>
/// <remarks>
/// <para>The possible values are: #mkldnn_scratchpad_mode_library (default) and</para>
/// <para>#mkldnn_scratchpad_mode_user.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetScratchpadMode(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnScratchpadModeT mode)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __ret = __Internal.MkldnnPrimitiveAttrSetScratchpadMode(__arg0, mode);
            return __ret;
        }

        /// <summary>
/// <para>Returnscorrespondence scaleand a pointer to a constant</para>
/// <para>floating point array of outputfor givenpreviously set</para>
/// <para>by mkldnn_primitive_attr_set_output_scales.</para>
/// </summary>
/// <remarks>
/// <para>Thearray points to the internalfield, so the user</para>
/// <para>should not modify or destroy</para>
/// <para>The lifetime ofis the same as that of theto which it</para>
/// <para>belongs, so it is illegal to useafteris destroyed.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrGetOutputScales(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, ref long count, ref int mask, float** scales)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            fixed (long* __count1 = &count)
            {
                var __arg1 = __count1;
                fixed (int* __mask2 = &mask)
                {
                    var __arg2 = __mask2;
                    var __ret = __Internal.MkldnnPrimitiveAttrGetOutputScales(__arg0, __arg1, __arg2, scales);
                    return __ret;
                }
            }
        }

        /// <summary>Sets outputfor primitive operations. The number of elementsand correspondence scaleare stored for future use.</summary>
/// <remarks>
/// <para>Theargument defines the correspondence between the output tensor</para>
/// <para>dimensions and thearray. Set the i-th bit ofto 1 to use a</para>
/// <para>dedicated scaling factor for each slice of the output tensor over the i-th</para>
/// <para>dimension. Setto 0 to use a common scaling factor for the whole</para>
/// <para>output tensor.</para>
/// <para>The dimension order is always native and does not depend on the actual</para>
/// <para>layout used. Examples:</para>
/// <para>- 2D dimensional data the order of dimensions is always: (n, c)</para>
/// <para>- 4D dimensional data the order is always: (n, c, h, w)</para>
/// <para>- 5D dimensional weights the order is always: (g, oc, ic, kh, kw)</para>
/// <para>Example usage:</para>
/// <para>There is no way to check thatcorresponds tountil an</para>
/// <para>actual primitive descriptor is created, so it is the user's</para>
/// <para>responsibility to set proper values. The following formula must hold:</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetOutputScales(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, long count, int mask, ref float scales)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            fixed (float* __scales3 = &scales)
            {
                var __arg3 = __scales3;
                var __ret = __Internal.MkldnnPrimitiveAttrSetOutputScales(__arg0, count, mask, __arg3);
                return __ret;
            }
        }

        /// <summary>Returnsfor given</summary>
/// <remarks>
/// <para>points to the internalfield, so the user should not</para>
/// <para>modify or destroyAlso, the lifetime ofis the</para>
/// <para>same as that of theit belongs to, so it is illegal to useafterhas been destroyed.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrGetPostOps(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnPostOps post_ops)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var ____arg1 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            var __arg1 = new global::System.IntPtr(&____arg1);
            var __ret = __Internal.MkldnnPrimitiveAttrGetPostOps(__arg0, __arg1);
            return __ret;
        }

        /// <summary>
/// <para>Sets configuredto an attributefor future use (when</para>
/// <para>primitive descriptor is being created).</para>
/// </summary>
/// <remarks>
/// <para>At this point in time, there is no way to check whether the primitive</para>
/// <para>descriptor does or does not support a given sequence of post operations.</para>
/// <para>Therefore the user should handle an error that might occur at the</para>
/// <para>mkldnn_primitive_desc_create call.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetPostOps(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnPostOps post_ops)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __arg1 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            var __ret = __Internal.MkldnnPrimitiveAttrSetPostOps(__arg0, __arg1);
            return __ret;
        }

        /// <summary>Creates an empty sequence of post operations</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsCreate(global::Intel.MklDnn.MkldnnPostOps post_ops)
        {
            var ____arg0 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __ret = __Internal.MkldnnPostOpsCreate(__arg0);
            return __ret;
        }

        /// <summary>Deletes asequence.</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsDestroy(global::Intel.MklDnn.MkldnnPostOps post_ops)
        {
            var __arg0 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            var __ret = __Internal.MkldnnPostOpsDestroy(__arg0);
            return __ret;
        }

        /// <summary>Returns theof post operations for given</summary>
        public static int MkldnnPostOpsLen(global::Intel.MklDnn.MkldnnPostOps post_ops)
        {
            var __arg0 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            var __ret = __Internal.MkldnnPostOpsLen(__arg0);
            return __ret;
        }

        /// <summary>
/// <para>Returns the kind of post operation with indexin given</para>
/// <para>In case of error, returns #mkldnn_undefined_primitive.</para>
/// </summary>
        public static global::Intel.MklDnn.MkldnnPrimitiveKindT MkldnnPostOpsGetKind(global::Intel.MklDnn.MkldnnPostOps post_ops, int index)
        {
            var __arg0 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            var __ret = __Internal.MkldnnPostOpsGetKind(__arg0, index);
            return __ret;
        }

        /// <summary>
/// <para>Appends accumulation (sum) post operation to thePrior to</para>
/// <para>accumulating the result, the previous value would be multiplied by</para>
/// </summary>
/// <remarks>
/// <para>The kind of this post operation is #mkldnn_sum.</para>
/// <para>This feature might improve performance for cases like residual learning</para>
/// <para>blocks, where the result of convolution is accumulated to the previously</para>
/// <para>computed activations. The parametermight be extreme for the</para>
/// <para>integer-based computations when the result and previous activations have</para>
/// <para>different logical scaling factors.</para>
/// <para>In the simplest case when the accumulation is the only post operation, the</para>
/// <para>computations would be:</para>
/// <para>dst[]&lt;&gt;- scale * dst[] + op(...) // instead of dst[]&lt;&gt;- op(...)</para>
/// <para>This post operation (as well as all the others) disregards the original</para>
/// <para>layout of the destination; that is, the layout of the original</para>
/// <para>destination is expected to be the same as the layout of the stored</para>
/// <para>destination.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsAppendSum(global::Intel.MklDnn.MkldnnPostOps post_ops, float scale)
        {
            var __arg0 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            var __ret = __Internal.MkldnnPostOpsAppendSum(__arg0, scale);
            return __ret;
        }

        /// <summary>
/// <para>Gets the parameters of the accumulation (sum) post operation with index</para>
/// <para>in the sequence of</para>
/// </summary>
/// <remarks>
/// <para>If indexwould not correspond to the accumulation post</para>
/// <para>operation, the function returns #mkldnn_invalid_arguments.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsGetParamsSum(global::Intel.MklDnn.MkldnnPostOps post_ops, int index, ref float scale)
        {
            var __arg0 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            fixed (float* __scale2 = &scale)
            {
                var __arg2 = __scale2;
                var __ret = __Internal.MkldnnPostOpsGetParamsSum(__arg0, index, __arg2);
                return __ret;
            }
        }

        /// <summary>
/// <para>Appends eltwise post operation to thewith given parameters</para>
/// <para>and(</para>
/// </summary>
/// <remarks>
/// <para>mkldnn_eltwise_forward_desc_init and</para>
/// <para>mkldnn_eltwise_desc_t).</para>
/// <para>The kind of this post operation is #mkldnn_eltwise.</para>
/// <para>In the simplest case when the eltwise is the only post operation, the</para>
/// <para>computations would be:</para>
/// <para>dst[]&lt;&gt;- scale * eltwise_op ( op(...) ) // instead of dst[]&lt;&gt;- op(...)</para>
/// <para>where eltwise_op is configured with the given parameters.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsAppendEltwise(global::Intel.MklDnn.MkldnnPostOps post_ops, float scale, global::Intel.MklDnn.MkldnnAlgKindT alg, float alpha, float beta)
        {
            var __arg0 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            var __ret = __Internal.MkldnnPostOpsAppendEltwise(__arg0, scale, alg, alpha, beta);
            return __ret;
        }

        /// <summary>
/// <para>Gets the eltwise parameters of the post operation with indexin</para>
/// <para>the sequence of</para>
/// </summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPostOpsGetParamsEltwise(global::Intel.MklDnn.MkldnnPostOps post_ops, int index, ref float scale, global::Intel.MklDnn.MkldnnAlgKindT* alg, ref float alpha, ref float beta)
        {
            var __arg0 = ReferenceEquals(post_ops, null) ? global::System.IntPtr.Zero : post_ops.__Instance;
            fixed (float* __scale2 = &scale)
            {
                var __arg2 = __scale2;
                fixed (float* __alpha4 = &alpha)
                {
                    var __arg4 = __alpha4;
                    fixed (float* __beta5 = &beta)
                    {
                        var __arg5 = __beta5;
                        var __ret = __Internal.MkldnnPostOpsGetParamsEltwise(__arg0, index, __arg2, alg, __arg4, __arg5);
                        return __ret;
                    }
                }
            }
        }

        /// <summary>Initializes amemory descriptor usingand</summary>
/// <remarks>
/// <para>Themight be NULL, which means the order of physical dimensions</para>
/// <para>is the same as the order of logical ones.</para>
/// <para>The logical order of dimensions is defined by a primitive that</para>
/// <para>consumes the memory.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryDescInitByStrides(global::Intel.MklDnn.MkldnnMemoryDescT memory_desc, int ndims, long[] dims, global::Intel.MklDnn.MkldnnDataTypeT data_type, long[] strides)
        {
            var __arg0 = ReferenceEquals(memory_desc, null) ? global::System.IntPtr.Zero : memory_desc.__Instance;
            if (dims == null || dims.Length != 12)
                throw new ArgumentOutOfRangeException("dims", "The dimensions of the provided array don't match the required size.");
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnMemoryDescInitByStrides(__arg0, ndims, dims, data_type, strides);
            return __ret;
        }

        /// <summary>Initializes amemory descriptor usingand format</summary>
/// <remarks>
/// <para>can be #mkldnn_format_tag_any, which allows a primitive to define</para>
/// <para>the appropriate memory format. In this case, thewould be set</para>
/// <para>to #mkldnn_format_kind_any</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryDescInitByTag(global::Intel.MklDnn.MkldnnMemoryDescT memory_desc, int ndims, long[] dims, global::Intel.MklDnn.MkldnnDataTypeT data_type, global::Intel.MklDnn.MkldnnFormatTagT tag)
        {
            var __arg0 = ReferenceEquals(memory_desc, null) ? global::System.IntPtr.Zero : memory_desc.__Instance;
            if (dims == null || dims.Length != 12)
                throw new ArgumentOutOfRangeException("dims", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnMemoryDescInitByTag(__arg0, ndims, dims, data_type, tag);
            return __ret;
        }

        /// <summary>
/// <para>Initializes afor a givenwith</para>
/// <para>sizes andMay fail if layout used does not allow</para>
/// <para>obtain desired submemory. In this case consider using `extract` or `insert`</para>
/// <para>primitive</para>
/// </summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryDescInitSubmemory(global::Intel.MklDnn.MkldnnMemoryDescT memory_desc, global::Intel.MklDnn.MkldnnMemoryDescT parent_memory_desc, long[] dims, long[] offsets)
        {
            var __arg0 = ReferenceEquals(memory_desc, null) ? global::System.IntPtr.Zero : memory_desc.__Instance;
            var __arg1 = ReferenceEquals(parent_memory_desc, null) ? global::System.IntPtr.Zero : parent_memory_desc.__Instance;
            if (dims == null || dims.Length != 12)
                throw new ArgumentOutOfRangeException("dims", "The dimensions of the provided array don't match the required size.");
            if (offsets == null || offsets.Length != 12)
                throw new ArgumentOutOfRangeException("offsets", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnMemoryDescInitSubmemory(__arg0, __arg1, dims, offsets);
            return __ret;
        }

        /// <summary>Compares two memory descriptors.</summary>
/// <returns>1 if the descriptors are the same.</returns>
/// <returns>
/// <para>0 if the descriptors are different.</para>
/// <para>Use this function to identify whether a reorder is required between the</para>
/// <para>two memories</para>
/// </returns>
        public static int MkldnnMemoryDescEqual(global::Intel.MklDnn.MkldnnMemoryDescT lhs, global::Intel.MklDnn.MkldnnMemoryDescT rhs)
        {
            var __arg0 = ReferenceEquals(lhs, null) ? global::System.IntPtr.Zero : lhs.__Instance;
            var __arg1 = ReferenceEquals(rhs, null) ? global::System.IntPtr.Zero : rhs.__Instance;
            var __ret = __Internal.MkldnnMemoryDescEqual(__arg0, __arg1);
            return __ret;
        }

        /// <summary>Returns the size (in bytes) that is required for given</summary>
        public static ulong MkldnnMemoryDescGetSize(global::Intel.MklDnn.MkldnnMemoryDescT memory_desc)
        {
            var __arg0 = ReferenceEquals(memory_desc, null) ? global::System.IntPtr.Zero : memory_desc.__Instance;
            var __ret = __Internal.MkldnnMemoryDescGetSize(__arg0);
            return __ret;
        }

        /// <summary>
/// <para>Creates a memory for givenandAlso setsto one of the following:</para>
/// <para>- pointer to the user allocated memory, i.e. valid handle. In this case the</para>
/// <para>library doesn't own allocated memory.</para>
/// <para>- MKLDNN_MEMORY_ALLOCATE to ask the library to allocate and</para>
/// <para>attach memory. In this case the library owns allocated memory.</para>
/// <para>- MKLDNN_MEMORY_NONE to create mkldnn_memory w/o attached memory.</para>
/// </summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryCreate(global::Intel.MklDnn.MkldnnMemory memory, global::Intel.MklDnn.MkldnnMemoryDescT memory_desc, global::Intel.MklDnn.MkldnnEngine engine, global::System.IntPtr handle)
        {
            var ____arg0 = ReferenceEquals(memory, null) ? global::System.IntPtr.Zero : memory.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg1 = ReferenceEquals(memory_desc, null) ? global::System.IntPtr.Zero : memory_desc.__Instance;
            var __arg2 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __ret = __Internal.MkldnnMemoryCreate(__arg0, __arg1, __arg2, handle);
            return __ret;
        }

        /// <summary>Returns aassociated with</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryGetMemoryDesc(global::Intel.MklDnn.MkldnnMemory memory, global::Intel.MklDnn.MkldnnMemoryDescT memory_desc)
        {
            var __arg0 = ReferenceEquals(memory, null) ? global::System.IntPtr.Zero : memory.__Instance;
            var ____arg1 = ReferenceEquals(memory_desc, null) ? global::System.IntPtr.Zero : memory_desc.__Instance;
            var __arg1 = new global::System.IntPtr(&____arg1);
            var __ret = __Internal.MkldnnMemoryGetMemoryDesc(__arg0, __arg1);
            return __ret;
        }

        /// <summary>Returns anassociated with</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryGetEngine(global::Intel.MklDnn.MkldnnMemory memory, global::Intel.MklDnn.MkldnnEngine engine)
        {
            var __arg0 = ReferenceEquals(memory, null) ? global::System.IntPtr.Zero : memory.__Instance;
            var ____arg1 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __arg1 = new global::System.IntPtr(&____arg1);
            var __ret = __Internal.MkldnnMemoryGetEngine(__arg0, __arg1);
            return __ret;
        }

        /// <summary>For amaps the data of the memory to</summary>
/// <remarks>
/// <para>Mapping allows to read/write directly from/to the memory contents for</para>
/// <para>engines that do not support direct memory access.</para>
/// <para>Mapping is an exclusive operation - a memory object cannot be used in other</para>
/// <para>operations until this memory object is unmapped.</para>
/// <para>Any primitives working withshould be completed before</para>
/// <para>mapping the memory. Use mkldnn_stream_wait to synchronize the</para>
/// <para>corresponding execution stream.</para>
/// <para>Map/unmap API is provided mainly for debug/testing purposes and its</para>
/// <para>performance may be suboptimal.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryMapData(global::Intel.MklDnn.MkldnnMemory memory, void** mapped_ptr)
        {
            var __arg0 = ReferenceEquals(memory, null) ? global::System.IntPtr.Zero : memory.__Instance;
            var __ret = __Internal.MkldnnMemoryMapData(__arg0, mapped_ptr);
            return __ret;
        }

        /// <summary>For aunmaps a mapped pointer to the data of the memory.</summary>
/// <remarks>
/// <para>Any changes of the mapped data are synchronized back to the memory after the</para>
/// <para>call is complete. The mapped pointer must be obtained through a</para>
/// <para>mkldnn_memory_map_data call.</para>
/// <para>Map/unmap API is provided mainly for debug/testing purposes and its</para>
/// <para>performance may be suboptimal.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryUnmapData(global::Intel.MklDnn.MkldnnMemory memory, global::System.IntPtr mapped_ptr)
        {
            var __arg0 = ReferenceEquals(memory, null) ? global::System.IntPtr.Zero : memory.__Instance;
            var __ret = __Internal.MkldnnMemoryUnmapData(__arg0, mapped_ptr);
            return __ret;
        }

        /// <summary>For areturns the data</summary>
/// <remarks>For the CPU engine, the data handle is a pointer to the actual data.</remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryGetDataHandle(global::Intel.MklDnn.MkldnnMemory memory, void** handle)
        {
            var __arg0 = ReferenceEquals(memory, null) ? global::System.IntPtr.Zero : memory.__Instance;
            var __ret = __Internal.MkldnnMemoryGetDataHandle(__arg0, handle);
            return __ret;
        }

        /// <summary>For asets the data</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemorySetDataHandle(global::Intel.MklDnn.MkldnnMemory memory, global::System.IntPtr handle)
        {
            var __arg0 = ReferenceEquals(memory, null) ? global::System.IntPtr.Zero : memory.__Instance;
            var __ret = __Internal.MkldnnMemorySetDataHandle(__arg0, handle);
            return __ret;
        }

        /// <summary>Deletes a</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnMemoryDestroy(global::Intel.MklDnn.MkldnnMemory memory)
        {
            var __arg0 = ReferenceEquals(memory, null) ? global::System.IntPtr.Zero : memory.__Instance;
            var __ret = __Internal.MkldnnMemoryDestroy(__arg0);
            return __ret;
        }

        /// <summary>
/// <para>Initializes ausing the description of the source</para>
/// <para>(andand destination (andmemory, and anattribute.</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- input (#mkldnn_query_src_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- output (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnReorderPrimitiveDescCreate(global::Intel.MklDnn.MkldnnPrimitiveDesc reorder_primitive_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_md, global::Intel.MklDnn.MkldnnEngine src_engine, global::Intel.MklDnn.MkldnnMemoryDescT dst_md, global::Intel.MklDnn.MkldnnEngine dst_engine, global::Intel.MklDnn.MkldnnPrimitiveAttr attr)
        {
            var ____arg0 = ReferenceEquals(reorder_primitive_desc, null) ? global::System.IntPtr.Zero : reorder_primitive_desc.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg1 = ReferenceEquals(src_md, null) ? global::System.IntPtr.Zero : src_md.__Instance;
            var __arg2 = ReferenceEquals(src_engine, null) ? global::System.IntPtr.Zero : src_engine.__Instance;
            var __arg3 = ReferenceEquals(dst_md, null) ? global::System.IntPtr.Zero : dst_md.__Instance;
            var __arg4 = ReferenceEquals(dst_engine, null) ? global::System.IntPtr.Zero : dst_engine.__Instance;
            var __arg5 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __ret = __Internal.MkldnnReorderPrimitiveDescCreate(__arg0, __arg1, __arg2, __arg3, __arg4, __arg5);
            return __ret;
        }

        /// <summary>
/// <para>Creates out-of-placefor concatenation ofinputs bywith resultingmemory</para>
/// <para>descriptor.can be NULL or specified with the</para>
/// <para>#mkldnn_format_kind_any format kind -- in this case, the appropriate memory</para>
/// <para>format would be chosen automatically.</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- input 0 (#mkldnn_query_src_md, 0)</para>
/// <para>- input 1 (#mkldnn_query_src_md, 1)</para>
/// <para>- ...</para>
/// <para>- input- 1 (#mkldnn_query_src_md,- 1)</para>
/// <para>Outputs:</para>
/// <para>- output (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnConcatPrimitiveDescCreate(global::Intel.MklDnn.MkldnnPrimitiveDesc concat_primitive_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_md, int n, int concat_dimension, global::Intel.MklDnn.MkldnnMemoryDescT src_mds, global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnEngine engine)
        {
            var ____arg0 = ReferenceEquals(concat_primitive_desc, null) ? global::System.IntPtr.Zero : concat_primitive_desc.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg1 = ReferenceEquals(dst_md, null) ? global::System.IntPtr.Zero : dst_md.__Instance;
            var __arg4 = ReferenceEquals(src_mds, null) ? global::System.IntPtr.Zero : src_mds.__Instance;
            var __arg5 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __arg6 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __ret = __Internal.MkldnnConcatPrimitiveDescCreate(__arg0, __arg1, n, concat_dimension, __arg4, __arg5, __arg6);
            return __ret;
        }

        /// <summary>
/// <para>Creates out-of-placefor sum ofinputs multiplied by scale with resultingmemory</para>
/// <para>descriptor.can be NULL or specified with the</para>
/// <para>#mkldnn_format_kind_any format kind -- in this case, the appropriate memory</para>
/// <para>format would be chosen automatically.</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- src 0 (#mkldnn_query_src_md, 0)</para>
/// <para>- src 1 (#mkldnn_query_src_md, 1)</para>
/// <para>- ...</para>
/// <para>- src- 1 (#mkldnn_query_src_md,- 1)</para>
/// <para>Outputs:</para>
/// <para>- output (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnSumPrimitiveDescCreate(global::Intel.MklDnn.MkldnnPrimitiveDesc sum_primitive_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_mds, int n, ref float scales, global::Intel.MklDnn.MkldnnMemoryDescT src_mds, global::Intel.MklDnn.MkldnnPrimitiveAttr attr, global::Intel.MklDnn.MkldnnEngine engine)
        {
            var ____arg0 = ReferenceEquals(sum_primitive_desc, null) ? global::System.IntPtr.Zero : sum_primitive_desc.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg1 = ReferenceEquals(dst_mds, null) ? global::System.IntPtr.Zero : dst_mds.__Instance;
            fixed (float* __scales3 = &scales)
            {
                var __arg3 = __scales3;
                var __arg4 = ReferenceEquals(src_mds, null) ? global::System.IntPtr.Zero : src_mds.__Instance;
                var __arg5 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
                var __arg6 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
                var __ret = __Internal.MkldnnSumPrimitiveDescCreate(__arg0, __arg1, n, __arg3, __arg4, __arg5, __arg6);
                return __ret;
            }
        }

        /// <summary>
/// <para>Initializes a convolution descriptorfor forward propagation</para>
/// <para>using(possible values are #mkldnn_forward_training and</para>
/// <para>#mkldnn_forward_inference),memory descriptors,andIn order to create a</para>
/// <para>convolution without bias,should either beor point to</para>
/// <para>a descriptor with memory format kind equal to #mkldnn_format_kind_undef.</para>
/// </summary>
/// <remarks>
/// <para>Ifisthe padding is supposed to be symmetric.</para>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>- bias (#mkldnn_query_weights_md, 1), if created with bias</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnConvolutionForwardDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_desc, long[] strides, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg3 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg4 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg5 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg6 = ReferenceEquals(dst_desc, null) ? global::System.IntPtr.Zero : dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnConvolutionForwardDescInit(__arg0, prop_kind, alg_kind, __arg3, __arg4, __arg5, __arg6, strides, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a dilated convolution descriptorfor forward</para>
/// <para>propagation using(possible values are #mkldnn_forward_training</para>
/// <para>and #mkldnn_forward_inference),memory descriptors,andIn order to create a dilated convolution without bias,should either beor point to a descriptor with memory format kind</para>
/// <para>equals #mkldnn_format_kind_undef.</para>
/// </summary>
/// <remarks>
/// <para>Ifisthe padding is supposed to be symmetric.</para>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>- bias (#mkldnn_query_weights_md, 1), if created with bias</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedConvolutionForwardDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg3 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg4 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg5 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg6 = ReferenceEquals(dst_desc, null) ? global::System.IntPtr.Zero : dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (dilates == null || dilates.Length != 12)
                throw new ArgumentOutOfRangeException("dilates", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDilatedConvolutionForwardDescInit(__arg0, prop_kind, alg_kind, __arg3, __arg4, __arg5, __arg6, strides, dilates, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a convolution descriptorfor backward propagation</para>
/// <para>with respect to data usingmemory descriptors,and</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnConvolutionBackwardDataDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_src_desc, null) ? global::System.IntPtr.Zero : diff_src_desc.__Instance;
            var __arg3 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnConvolutionBackwardDataDescInit(__arg0, alg_kind, __arg2, __arg3, __arg4, strides, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a dilated convolution descriptorfor backward</para>
/// <para>propagation with respect to data usingmemory descriptors,and</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedConvolutionBackwardDataDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_src_desc, null) ? global::System.IntPtr.Zero : diff_src_desc.__Instance;
            var __arg3 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (dilates == null || dilates.Length != 12)
                throw new ArgumentOutOfRangeException("dilates", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDilatedConvolutionBackwardDataDescInit(__arg0, alg_kind, __arg2, __arg3, __arg4, strides, dilates, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a convolution descriptorfor backward propagation</para>
/// <para>with respect to weights usingmemory descriptors,and</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_weights (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 1), if created with bias</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnConvolutionBackwardWeightsDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg2 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg3 = ReferenceEquals(diff_weights_desc, null) ? global::System.IntPtr.Zero : diff_weights_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg5 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnConvolutionBackwardWeightsDescInit(__arg0, alg_kind, __arg2, __arg3, __arg4, __arg5, strides, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a convolution descriptorfor backward propagation</para>
/// <para>with respect to weights usingmemory descriptors,and</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_weights (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 1), if created with bias</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedConvolutionBackwardWeightsDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg2 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg3 = ReferenceEquals(diff_weights_desc, null) ? global::System.IntPtr.Zero : diff_weights_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg5 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (dilates == null || dilates.Length != 12)
                throw new ArgumentOutOfRangeException("dilates", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDilatedConvolutionBackwardWeightsDescInit(__arg0, alg_kind, __arg2, __arg3, __arg4, __arg5, strides, dilates, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a deconvolution descriptorfor forward</para>
/// <para>propagation using(possible values are #mkldnn_forward_training</para>
/// <para>and #mkldnn_forward_inference),memory descriptors,andIn order to create a</para>
/// <para>deconvolution without bias,should either beor point to</para>
/// <para>a descriptor with memory format kind equals #mkldnn_format_kind_undef.</para>
/// </summary>
/// <remarks>
/// <para>Ifisthe padding is supposed to be symmetric.</para>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>- bias (#mkldnn_query_weights_md, 1), if created with bias</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDeconvolutionForwardDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_desc, long[] strides, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg3 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg4 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg5 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg6 = ReferenceEquals(dst_desc, null) ? global::System.IntPtr.Zero : dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDeconvolutionForwardDescInit(__arg0, prop_kind, alg_kind, __arg3, __arg4, __arg5, __arg6, strides, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a dilated deconvolution descriptorfor forward</para>
/// <para>propagation using(possible values are #mkldnn_forward_training</para>
/// <para>and #mkldnn_forward_inference),memory descriptors,andIn order to</para>
/// <para>create a dilated deconvolution without bias,should either be</para>
/// <para>or point to a descriptor with memory format kind equal</para>
/// <para>#mkldnn_format_kind_undef.</para>
/// </summary>
/// <remarks>
/// <para>Ifisthe padding is supposed to be symmetric.</para>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>- bias (#mkldnn_query_weights_md, 1), if created with bias</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedDeconvolutionForwardDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg3 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg4 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg5 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg6 = ReferenceEquals(dst_desc, null) ? global::System.IntPtr.Zero : dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (dilates == null || dilates.Length != 12)
                throw new ArgumentOutOfRangeException("dilates", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDilatedDeconvolutionForwardDescInit(__arg0, prop_kind, alg_kind, __arg3, __arg4, __arg5, __arg6, strides, dilates, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a deconvolution descriptorfor backward propagation</para>
/// <para>with respect to data usingmemory descriptors,and</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDeconvolutionBackwardDataDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_src_desc, null) ? global::System.IntPtr.Zero : diff_src_desc.__Instance;
            var __arg3 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDeconvolutionBackwardDataDescInit(__arg0, alg_kind, __arg2, __arg3, __arg4, strides, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a dilated deconvolution descriptorfor backward</para>
/// <para>propagation with respect to data usingmemory descriptors,and</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedDeconvolutionBackwardDataDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_src_desc, null) ? global::System.IntPtr.Zero : diff_src_desc.__Instance;
            var __arg3 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (dilates == null || dilates.Length != 12)
                throw new ArgumentOutOfRangeException("dilates", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDilatedDeconvolutionBackwardDataDescInit(__arg0, alg_kind, __arg2, __arg3, __arg4, strides, dilates, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a deconvolution descriptorfor backward propagation</para>
/// <para>with respect to weights usingmemory descriptors,and</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_weights (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 1), if created with bias</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDeconvolutionBackwardWeightsDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg2 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg3 = ReferenceEquals(diff_weights_desc, null) ? global::System.IntPtr.Zero : diff_weights_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg5 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDeconvolutionBackwardWeightsDescInit(__arg0, alg_kind, __arg2, __arg3, __arg4, __arg5, strides, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a dilated deconvolution descriptorfor backward</para>
/// <para>propagation with respect to weights usingmemory descriptors,</para>
/// <para>and</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_weights (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 1), if created with bias</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnDilatedDeconvolutionBackwardWeightsDescInit(global::Intel.MklDnn.MkldnnConvolutionDescT conv_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] dilates, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(conv_desc, null) ? global::System.IntPtr.Zero : conv_desc.__Instance;
            var __arg2 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg3 = ReferenceEquals(diff_weights_desc, null) ? global::System.IntPtr.Zero : diff_weights_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg5 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (dilates == null || dilates.Length != 12)
                throw new ArgumentOutOfRangeException("dilates", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnDilatedDeconvolutionBackwardWeightsDescInit(__arg0, alg_kind, __arg2, __arg3, __arg4, __arg5, strides, dilates, padding_l, padding_r);
            return __ret;
        }

        /// <summary>Initializes afor forward propagation usingmemory descriptorand</summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnShuffleForwardDescInit(global::Intel.MklDnn.MkldnnShuffleDescT shuffle_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, int axis, long group_size)
        {
            var __arg0 = ReferenceEquals(shuffle_desc, null) ? global::System.IntPtr.Zero : shuffle_desc.__Instance;
            var __arg2 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnShuffleForwardDescInit(__arg0, prop_kind, __arg2, axis, group_size);
            return __ret;
        }

        /// <summary>
/// <para>Initializes afor backward propagation using memory</para>
/// <para>descriptorand</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnShuffleBackwardDescInit(global::Intel.MklDnn.MkldnnShuffleDescT shuffle_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_data_desc, int axis, long group_size)
        {
            var __arg0 = ReferenceEquals(shuffle_desc, null) ? global::System.IntPtr.Zero : shuffle_desc.__Instance;
            var __arg1 = ReferenceEquals(diff_data_desc, null) ? global::System.IntPtr.Zero : diff_data_desc.__Instance;
            var __ret = __Internal.MkldnnShuffleBackwardDescInit(__arg0, __arg1, axis, group_size);
            return __ret;
        }

        /// <summary>
/// <para>Initializes anfor forward propagation using(possible values are #mkldnn_forward_training and #mkldnn_forward_inference),</para>
/// <para>algorithm, memory descriptorand</para>
/// <para>parameters.</para>
/// </summary>
/// <remarks>
/// <para>mkldnn_eltwise_desc_t for details.</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnEltwiseForwardDescInit(global::Intel.MklDnn.MkldnnEltwiseDescT eltwise_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, float alpha, float beta)
        {
            var __arg0 = ReferenceEquals(eltwise_desc, null) ? global::System.IntPtr.Zero : eltwise_desc.__Instance;
            var __arg3 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnEltwiseForwardDescInit(__arg0, prop_kind, alg_kind, __arg3, alpha, beta);
            return __ret;
        }

        /// <summary>
/// <para>Initializes anfor backward propagation usingalgorithm memory descriptorsandand the</para>
/// <para>andparameters.</para>
/// </summary>
/// <remarks>
/// <para>mkldnn_eltwise_desc_t for details.</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnEltwiseBackwardDescInit(global::Intel.MklDnn.MkldnnEltwiseDescT eltwise_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT diff_data_desc, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, float alpha, float beta)
        {
            var __arg0 = ReferenceEquals(eltwise_desc, null) ? global::System.IntPtr.Zero : eltwise_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_data_desc, null) ? global::System.IntPtr.Zero : diff_data_desc.__Instance;
            var __arg3 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnEltwiseBackwardDescInit(__arg0, alg_kind, __arg2, __arg3, alpha, beta);
            return __ret;
        }

        /// <summary>
/// <para>Initializes afor forward propagation using(possible values are #mkldnn_forward_training and #mkldnn_forward_inference)</para>
/// <para>and memory descriptor</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnSoftmaxForwardDescInit(global::Intel.MklDnn.MkldnnSoftmaxDescT softmax_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, int softmax_axis)
        {
            var __arg0 = ReferenceEquals(softmax_desc, null) ? global::System.IntPtr.Zero : softmax_desc.__Instance;
            var __arg2 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnSoftmaxForwardDescInit(__arg0, prop_kind, __arg2, softmax_axis);
            return __ret;
        }

        /// <summary>
/// <para>Initializes afor backward propagation using memory</para>
/// <para>descriptorsand</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnSoftmaxBackwardDescInit(global::Intel.MklDnn.MkldnnSoftmaxDescT softmax_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_desc, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, int softmax_axis)
        {
            var __arg0 = ReferenceEquals(softmax_desc, null) ? global::System.IntPtr.Zero : softmax_desc.__Instance;
            var __arg1 = ReferenceEquals(diff_desc, null) ? global::System.IntPtr.Zero : diff_desc.__Instance;
            var __arg2 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnSoftmaxBackwardDescInit(__arg0, __arg1, __arg2, softmax_axis);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a pooling descriptorfor forward propagation using</para>
/// <para>(possible values are #mkldnn_forward_training and</para>
/// <para>#mkldnn_forward_inference),memory descriptors, and pooling</para>
/// <para>parameters in the spatial domain:sizes,and</para>
/// </summary>
/// <remarks>
/// <para>Ifisthe padding is supposed to be symmetric.</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>if= #mkldnn_pooling_max and</para>
/// <para>= #mkldnn_forward_training</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPoolingForwardDescInit(global::Intel.MklDnn.MkldnnPoolingDescT pool_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_desc, long[] strides, long[] kernel, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(pool_desc, null) ? global::System.IntPtr.Zero : pool_desc.__Instance;
            var __arg3 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg4 = ReferenceEquals(dst_desc, null) ? global::System.IntPtr.Zero : dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (kernel == null || kernel.Length != 12)
                throw new ArgumentOutOfRangeException("kernel", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnPoolingForwardDescInit(__arg0, prop_kind, alg_kind, __arg3, __arg4, strides, kernel, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a pooling descriptorfor backward propagation</para>
/// <para>usingmemory descriptors, and pooling parameters in the spatial</para>
/// <para>domain:sizes,and</para>
/// </summary>
/// <remarks>
/// <para>Ifisthe padding is supposed to be symmetric.</para>
/// <para>Inputs:</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>if= #mkldnn_pooling_max</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPoolingBackwardDescInit(global::Intel.MklDnn.MkldnnPoolingDescT pool_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc, long[] strides, long[] kernel, long[] padding_l, long[] padding_r)
        {
            var __arg0 = ReferenceEquals(pool_desc, null) ? global::System.IntPtr.Zero : pool_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_src_desc, null) ? global::System.IntPtr.Zero : diff_src_desc.__Instance;
            var __arg3 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            if (strides == null || strides.Length != 12)
                throw new ArgumentOutOfRangeException("strides", "The dimensions of the provided array don't match the required size.");
            if (kernel == null || kernel.Length != 12)
                throw new ArgumentOutOfRangeException("kernel", "The dimensions of the provided array don't match the required size.");
            if (padding_l == null || padding_l.Length != 12)
                throw new ArgumentOutOfRangeException("padding_l", "The dimensions of the provided array don't match the required size.");
            if (padding_r == null || padding_r.Length != 12)
                throw new ArgumentOutOfRangeException("padding_r", "The dimensions of the provided array don't match the required size.");
            var __ret = __Internal.MkldnnPoolingBackwardDescInit(__arg0, alg_kind, __arg2, __arg3, strides, kernel, padding_l, padding_r);
            return __ret;
        }

        /// <summary>
/// <para>Initializes anfor forward propagation using(possible values are #mkldnn_forward_training and #mkldnn_forward_inference),</para>
/// <para>memory descriptorand regularization</para>
/// <para>parametersand</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>if the underlying implementation requires</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnLrnForwardDescInit(global::Intel.MklDnn.MkldnnLrnDescT lrn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, long local_size, float alpha, float beta, float k)
        {
            var __arg0 = ReferenceEquals(lrn_desc, null) ? global::System.IntPtr.Zero : lrn_desc.__Instance;
            var __arg3 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnLrnForwardDescInit(__arg0, prop_kind, alg_kind, __arg3, local_size, alpha, beta, k);
            return __ret;
        }

        /// <summary>
/// <para>Initializes anfor backward propagation usingmemory descriptorsandand regularization</para>
/// <para>parametersand</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>if the underlying implementation requires</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnLrnBackwardDescInit(global::Intel.MklDnn.MkldnnLrnDescT lrn_desc, global::Intel.MklDnn.MkldnnAlgKindT alg_kind, global::Intel.MklDnn.MkldnnMemoryDescT diff_data_desc, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, long local_size, float alpha, float beta, float k)
        {
            var __arg0 = ReferenceEquals(lrn_desc, null) ? global::System.IntPtr.Zero : lrn_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_data_desc, null) ? global::System.IntPtr.Zero : diff_data_desc.__Instance;
            var __arg3 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnLrnBackwardDescInit(__arg0, alg_kind, __arg2, __arg3, local_size, alpha, beta, k);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a batch normalization descriptorfor forward</para>
/// <para>propagation using(possible values are</para>
/// <para>#mkldnn_forward_training and #mkldnn_forward_inference), memory descriptor</para>
/// <para>normalization parameterandset using bit</para>
/// <para>flags of type mkldnn_batch_normalization_desc_t.</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- mean (#mkldnn_query_src_md, 1),</para>
/// <para>if #mkldnn_use_global_stats bit-flags is set in- variance (#mkldnn_query_src_md, 2),</para>
/// <para>if #mkldnn_use_global_stats bit-flags is set in- scale_and_shift (#mkldnn_query_weights_md, 0),</para>
/// <para>if #mkldnn_use_scaleshift bit-flags is set in</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// <para>- mean (#mkldnn_query_dst_md, 1),</para>
/// <para>if #mkldnn_use_global_stats bit-flags is not set in= #mkldnn_forward_training</para>
/// <para>- variance (#mkldnn_query_dst_md, 2),</para>
/// <para>if #mkldnn_use_global_stats bit-flags is not set inand= #mkldnn_forward_training</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>if #mkldnn_fuse_norm_relu bit-flags is set inand= #mkldnn_forward_training</para>
/// <para>In-place operation is supported; that is, dst points to the same memory</para>
/// <para>as src.</para>
/// <para>mkldnn_batch_normalization_desc_t</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnBatchNormalizationForwardDescInit(global::Intel.MklDnn.MkldnnBatchNormalizationDescT bnrm_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, float epsilon, uint flags)
        {
            var __arg0 = ReferenceEquals(bnrm_desc, null) ? global::System.IntPtr.Zero : bnrm_desc.__Instance;
            var __arg2 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnBatchNormalizationForwardDescInit(__arg0, prop_kind, __arg2, epsilon, flags);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a batch normalization descriptorfor backward</para>
/// <para>propagation with respect to data and scale-shift parameters using memory</para>
/// <para>descriptorsandnormalization parameter</para>
/// <para>andset using bit flags of type</para>
/// <para>mkldnn_batch_normalization_desc_t.</para>
/// </summary>
/// <remarks>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- mean (#mkldnn_query_src_md, 1)</para>
/// <para>- variance (#mkldnn_query_src_md, 2)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- scale_and_shift (#mkldnn_query_weights_md, 0),</para>
/// <para>if #mkldnn_use_scaleshift bit-flags is set in- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>if #mkldnn_fuse_norm_relu bit-flags is set in</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// <para>- diff_scale_and_shift (#mkldnn_query_diff_weights_md, 0),</para>
/// <para>if #mkldnn_use_scaleshift bit-flags is set inand= #mkldnn_backward</para>
/// <para>in-place operation is supported,</para>
/// <para>i.e. diff_src points to the same memory as diff_dst.</para>
/// <para>mkldnn_batch_normalization_desc_t</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnBatchNormalizationBackwardDescInit(global::Intel.MklDnn.MkldnnBatchNormalizationDescT bnrm_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnMemoryDescT diff_data_desc, global::Intel.MklDnn.MkldnnMemoryDescT data_desc, float epsilon, uint flags)
        {
            var __arg0 = ReferenceEquals(bnrm_desc, null) ? global::System.IntPtr.Zero : bnrm_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_data_desc, null) ? global::System.IntPtr.Zero : diff_data_desc.__Instance;
            var __arg3 = ReferenceEquals(data_desc, null) ? global::System.IntPtr.Zero : data_desc.__Instance;
            var __ret = __Internal.MkldnnBatchNormalizationBackwardDescInit(__arg0, prop_kind, __arg2, __arg3, epsilon, flags);
            return __ret;
        }

        /// <summary>
/// <para>Initializes an inner product descriptorfor forward propagation</para>
/// <para>using(possible values are #mkldnn_forward_training and</para>
/// <para>#mkldnn_forward_inference) and memory descriptors. In order to create an</para>
/// <para>inner product without bias,should be eitheror a</para>
/// <para>pointer to a descriptor with memory format kind equals</para>
/// <para>#mkldnn_format_kind_undef.</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>- bias (#mkldnn_query_weights_md, 1), if created with bias</para>
/// <para>Outputs:</para>
/// <para>- dst (#mkldnn_query_dst_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnInnerProductForwardDescInit(global::Intel.MklDnn.MkldnnInnerProductDescT ip_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_desc)
        {
            var __arg0 = ReferenceEquals(ip_desc, null) ? global::System.IntPtr.Zero : ip_desc.__Instance;
            var __arg2 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg3 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg4 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg5 = ReferenceEquals(dst_desc, null) ? global::System.IntPtr.Zero : dst_desc.__Instance;
            var __ret = __Internal.MkldnnInnerProductForwardDescInit(__arg0, prop_kind, __arg2, __arg3, __arg4, __arg5);
            return __ret;
        }

        /// <summary>
/// <para>Initializes an inner product descriptorfor backward propagation</para>
/// <para>with respect to data using memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- weights (#mkldnn_query_weights_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src (#mkldnn_query_diff_src_md, 0)</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnInnerProductBackwardDataDescInit(global::Intel.MklDnn.MkldnnInnerProductDescT ip_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc)
        {
            var __arg0 = ReferenceEquals(ip_desc, null) ? global::System.IntPtr.Zero : ip_desc.__Instance;
            var __arg1 = ReferenceEquals(diff_src_desc, null) ? global::System.IntPtr.Zero : diff_src_desc.__Instance;
            var __arg2 = ReferenceEquals(weights_desc, null) ? global::System.IntPtr.Zero : weights_desc.__Instance;
            var __arg3 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            var __ret = __Internal.MkldnnInnerProductBackwardDataDescInit(__arg0, __arg1, __arg2, __arg3);
            return __ret;
        }

        /// <summary>
/// <para>Initializes an inner product descriptorfor backward propagation</para>
/// <para>with respect to weights using memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>Memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Inputs:</para>
/// <para>- src (#mkldnn_query_src_md, 0)</para>
/// <para>- diff_dst (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_weights (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 1), if created with bias</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnInnerProductBackwardWeightsDescInit(global::Intel.MklDnn.MkldnnInnerProductDescT ip_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_desc)
        {
            var __arg0 = ReferenceEquals(ip_desc, null) ? global::System.IntPtr.Zero : ip_desc.__Instance;
            var __arg1 = ReferenceEquals(src_desc, null) ? global::System.IntPtr.Zero : src_desc.__Instance;
            var __arg2 = ReferenceEquals(diff_weights_desc, null) ? global::System.IntPtr.Zero : diff_weights_desc.__Instance;
            var __arg3 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg4 = ReferenceEquals(diff_dst_desc, null) ? global::System.IntPtr.Zero : diff_dst_desc.__Instance;
            var __ret = __Internal.MkldnnInnerProductBackwardWeightsDescInit(__arg0, __arg1, __arg2, __arg3, __arg4);
            return __ret;
        }

        /// <summary>
/// <para>Sets quantizationandfor RNN data tensors.</para>
/// <para>For performance reasons, low precision configuration of RNN primitive</para>
/// <para>expects input activations to have unsigned int8 data type. Scale and shift</para>
/// <para>used to quantize floating point data to unsigned integer must be passed to</para>
/// <para>RNN primitive using attributes.</para>
/// <para>Example usage:</para>
/// </summary>
/// <remarks>
/// <para>Quantization scale and shift are common for src_layer, src_iter,</para>
/// <para>dst_iter and dst_layer.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetRnnDataQparams(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, float scale, float shift)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            var __ret = __Internal.MkldnnPrimitiveAttrSetRnnDataQparams(__arg0, scale, shift);
            return __ret;
        }

        /// <summary>
/// <para>Sets quantization scalesfor RNN weights tensors.</para>
/// <para>Low precision configuration of RNN primitive expects input weights to have</para>
/// <para>signed int8 data type. Scales used to quantize floating point data</para>
/// <para>to signed integer must be passed to RNN primitive using attributes.</para>
/// <para>Theargument defines correspondence between output tensor dimensions</para>
/// <para>and thearray. Set i-th bit ofto 1 to use</para>
/// <para>dedicated scaling factor for each slice of the output tensor over i-th</para>
/// <para>dimension. Setto 0 to use common scaling factor for the whole output</para>
/// <para>tensor. Example usage:</para>
/// </summary>
/// <remarks>
/// <para>The dimension order is always native and does not depend on the actual</para>
/// <para>layout used. For example, 5 dimensional weights always have</para>
/// <para>(l, d, i, g, o) logical dimension ordering.</para>
/// <para>Quantization sales are common for weights_layer and weights_iteration</para>
/// <para>There is no way to check thatcorresponds tountil an</para>
/// <para>actual primitive descriptor is created, so it is user's responsibility</para>
/// <para>to set proper values. The following formula must be held:</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnPrimitiveAttrSetRnnWeightsQparams(global::Intel.MklDnn.MkldnnPrimitiveAttr attr, long count, int mask, ref float weights_scales)
        {
            var __arg0 = ReferenceEquals(attr, null) ? global::System.IntPtr.Zero : attr.__Instance;
            fixed (float* __weights_scales3 = &weights_scales)
            {
                var __arg3 = __weights_scales3;
                var __ret = __Internal.MkldnnPrimitiveAttrSetRnnWeightsQparams(__arg0, count, mask, __arg3);
                return __ret;
            }
        }

        /// <summary>
/// <para>Initializes an RNN descriptorfor forward propagation</para>
/// <para>usingand memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>Ifequals #mkldnn_forward_training, you must query a</para>
/// <para>workspace memory descriptor before creating the primitive.</para>
/// <para>andare allowed to either be</para>
/// <para>or point to a zero memory descriptor, which would indicate that the</para>
/// <para>RNN primitive should not use them and will default to zero values.</para>
/// <para>All memory descriptorsare allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>Parameters:</para>
/// <para>- activation (#mkldnn_eltwise_relu, #mkldnn_eltwise_tanh or #mkldnn_eltwise_logistic)</para>
/// <para>- alpha (negative slope if activation is #mkldnn_eltwise_relu)</para>
/// <para>- beta (unused for now)</para>
/// <para>- flags (unused for now)</para>
/// <para>Inputs:</para>
/// <para>- src_layer (#mkldnn_query_src_md, 0)</para>
/// <para>- src_iter (#mkldnn_query_src_md, 1), if used</para>
/// <para>- weights_layer (#mkldnn_query_weights_md, 0)</para>
/// <para>- weights_iter (#mkldnn_query_weights_md, 1)</para>
/// <para>- bias (#mkldnn_query_weights_md, 2), if used</para>
/// <para>Outputs:</para>
/// <para>- dst_layer (#mkldnn_query_dst_md, 0)</para>
/// <para>- dst_iter (#mkldnn_query_dst_md, 1), if used</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>ifequals #mkldnn_forward_training</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnVanillaRnnForwardDescInit(global::Intel.MklDnn.MkldnnRnnDescT rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT activation, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::Intel.MklDnn.MkldnnMemoryDescT src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_desc, uint flags, float alpha, float beta)
        {
            var __arg0 = ReferenceEquals(rnn_desc, null) ? global::System.IntPtr.Zero : rnn_desc.__Instance;
            var __arg4 = ReferenceEquals(src_layer_desc, null) ? global::System.IntPtr.Zero : src_layer_desc.__Instance;
            var __arg5 = ReferenceEquals(src_iter_desc, null) ? global::System.IntPtr.Zero : src_iter_desc.__Instance;
            var __arg6 = ReferenceEquals(weights_layer_desc, null) ? global::System.IntPtr.Zero : weights_layer_desc.__Instance;
            var __arg7 = ReferenceEquals(weights_iter_desc, null) ? global::System.IntPtr.Zero : weights_iter_desc.__Instance;
            var __arg8 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg9 = ReferenceEquals(dst_layer_desc, null) ? global::System.IntPtr.Zero : dst_layer_desc.__Instance;
            var __arg10 = ReferenceEquals(dst_iter_desc, null) ? global::System.IntPtr.Zero : dst_iter_desc.__Instance;
            var __ret = __Internal.MkldnnVanillaRnnForwardDescInit(__arg0, prop_kind, activation, direction, __arg4, __arg5, __arg6, __arg7, __arg8, __arg9, __arg10, flags, alpha, beta);
            return __ret;
        }

        /// <summary>
/// <para>Initializes an RNN descriptorfor backward propagation</para>
/// <para>usingand memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>All memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>(simultaneously with(simultaneously withand</para>
/// <para>(simultaneously withare allowed to</para>
/// <para>either beor point to a zero memory descriptor, which would indicate</para>
/// <para>that the RNN primitive should not use them and will default to zero values.</para>
/// <para>Parameters:</para>
/// <para>- activation (#mkldnn_eltwise_relu, #mkldnn_eltwise_tanh or #mkldnn_eltwise_logistic)</para>
/// <para>- alpha (negative slope if activation is #mkldnn_eltwise_relu)</para>
/// <para>- beta (unused for now)</para>
/// <para>- flags (unused for now)</para>
/// <para>Inputs:</para>
/// <para>- src_layer (#mkldnn_query_src_md, 0)</para>
/// <para>- src_iter (#mkldnn_query_src_md, 1), if used</para>
/// <para>- weights_layer (#mkldnn_query_weights_md, 0)</para>
/// <para>- weights_iter (#mkldnn_query_weights_md, 1)</para>
/// <para>- bias (#mkldnn_query_weights_md, 2), if used</para>
/// <para>- dst_layer (#mkldnn_query_dst_md, 0)</para>
/// <para>- dst_iter (#mkldnn_query_dst_md, 1), if used</para>
/// <para>- diff_dst_layer (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- diff_dst_iter (#mkldnn_query_diff_dst_md, 1), if used</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src_layer (#mkldnn_query_diff_src_md, 0)</para>
/// <para>- diff_src_iter (#mkldnn_query_diff_src_md, 1), if used</para>
/// <para>- diff_weights_layer (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_weights_iter (#mkldnn_query_diff_weights_md, 1)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 2), if used</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnVanillaRnnBackwardDescInit(global::Intel.MklDnn.MkldnnRnnDescT rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnAlgKindT activation, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::Intel.MklDnn.MkldnnMemoryDescT src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_iter_desc, uint flags, float alpha, float beta)
        {
            var __arg0 = ReferenceEquals(rnn_desc, null) ? global::System.IntPtr.Zero : rnn_desc.__Instance;
            var __arg4 = ReferenceEquals(src_layer_desc, null) ? global::System.IntPtr.Zero : src_layer_desc.__Instance;
            var __arg5 = ReferenceEquals(src_iter_desc, null) ? global::System.IntPtr.Zero : src_iter_desc.__Instance;
            var __arg6 = ReferenceEquals(weights_layer_desc, null) ? global::System.IntPtr.Zero : weights_layer_desc.__Instance;
            var __arg7 = ReferenceEquals(weights_iter_desc, null) ? global::System.IntPtr.Zero : weights_iter_desc.__Instance;
            var __arg8 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg9 = ReferenceEquals(dst_layer_desc, null) ? global::System.IntPtr.Zero : dst_layer_desc.__Instance;
            var __arg10 = ReferenceEquals(dst_iter_desc, null) ? global::System.IntPtr.Zero : dst_iter_desc.__Instance;
            var __arg11 = ReferenceEquals(diff_src_layer_desc, null) ? global::System.IntPtr.Zero : diff_src_layer_desc.__Instance;
            var __arg12 = ReferenceEquals(diff_src_iter_desc, null) ? global::System.IntPtr.Zero : diff_src_iter_desc.__Instance;
            var __arg13 = ReferenceEquals(diff_weights_layer_desc, null) ? global::System.IntPtr.Zero : diff_weights_layer_desc.__Instance;
            var __arg14 = ReferenceEquals(diff_weights_iter_desc, null) ? global::System.IntPtr.Zero : diff_weights_iter_desc.__Instance;
            var __arg15 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg16 = ReferenceEquals(diff_dst_layer_desc, null) ? global::System.IntPtr.Zero : diff_dst_layer_desc.__Instance;
            var __arg17 = ReferenceEquals(diff_dst_iter_desc, null) ? global::System.IntPtr.Zero : diff_dst_iter_desc.__Instance;
            var __ret = __Internal.MkldnnVanillaRnnBackwardDescInit(__arg0, prop_kind, activation, direction, __arg4, __arg5, __arg6, __arg7, __arg8, __arg9, __arg10, __arg11, __arg12, __arg13, __arg14, __arg15, __arg16, __arg17, flags, alpha, beta);
            return __ret;
        }

        /// <summary>
/// <para>Initializes an LSTM descriptorfor forward propagation</para>
/// <para>usingand memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>Ifequals #mkldnn_forward_training, you must query a</para>
/// <para>workspace memory descriptor before creating the primitive.</para>
/// <para>andare allowed to either be</para>
/// <para>or point to a zero memory descriptor, which would indicate that the</para>
/// <para>RNN primitive should not use them and will default to zero values.</para>
/// <para>All memory descriptors exceptare allowed to be</para>
/// <para>initialized with #mkldnn_format_kind_any value of</para>
/// <para>Parameters:</para>
/// <para>- flags (unused for now)</para>
/// <para>Inputs:</para>
/// <para>- src_layer (#mkldnn_query_src_md, 0)</para>
/// <para>- src_iter (#mkldnn_query_src_md, 1), if used</para>
/// <para>- src_iter_c (#mkldnn_query_src_md, 2), if used</para>
/// <para>- weights_layer (#mkldnn_query_weights_md, 0)</para>
/// <para>- weights_iter (#mkldnn_query_weights_md, 1)</para>
/// <para>- bias (#mkldnn_query_weights_md, 2), if used</para>
/// <para>Outputs:</para>
/// <para>- dst_layer (#mkldnn_query_dst_md, 0)</para>
/// <para>- dst_iter (#mkldnn_query_dst_md, 1), if used</para>
/// <para>- dst_iter_c (#mkldnn_query_dst_md, 2), if used</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>ifequals #mkldnn_forward_training</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnLstmForwardDescInit(global::Intel.MklDnn.MkldnnRnnDescT rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::Intel.MklDnn.MkldnnMemoryDescT src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_c_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_c_desc, uint flags)
        {
            var __arg0 = ReferenceEquals(rnn_desc, null) ? global::System.IntPtr.Zero : rnn_desc.__Instance;
            var __arg3 = ReferenceEquals(src_layer_desc, null) ? global::System.IntPtr.Zero : src_layer_desc.__Instance;
            var __arg4 = ReferenceEquals(src_iter_desc, null) ? global::System.IntPtr.Zero : src_iter_desc.__Instance;
            var __arg5 = ReferenceEquals(src_iter_c_desc, null) ? global::System.IntPtr.Zero : src_iter_c_desc.__Instance;
            var __arg6 = ReferenceEquals(weights_layer_desc, null) ? global::System.IntPtr.Zero : weights_layer_desc.__Instance;
            var __arg7 = ReferenceEquals(weights_iter_desc, null) ? global::System.IntPtr.Zero : weights_iter_desc.__Instance;
            var __arg8 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg9 = ReferenceEquals(dst_layer_desc, null) ? global::System.IntPtr.Zero : dst_layer_desc.__Instance;
            var __arg10 = ReferenceEquals(dst_iter_desc, null) ? global::System.IntPtr.Zero : dst_iter_desc.__Instance;
            var __arg11 = ReferenceEquals(dst_iter_c_desc, null) ? global::System.IntPtr.Zero : dst_iter_c_desc.__Instance;
            var __ret = __Internal.MkldnnLstmForwardDescInit(__arg0, prop_kind, direction, __arg3, __arg4, __arg5, __arg6, __arg7, __arg8, __arg9, __arg10, __arg11, flags);
            return __ret;
        }

        /// <summary>
/// <para>Initializes an LSTM descriptorfor backward propagation</para>
/// <para>usingand memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>All memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>(simultaneously with(simultaneously withand</para>
/// <para>(simultaneously withare allowed to</para>
/// <para>either beor point to a zero memory descriptor, which would indicate</para>
/// <para>that the RNN primitive should not use them and will default to zero values.</para>
/// <para>Parameters:</para>
/// <para>- flags (unused for now)</para>
/// <para>Inputs:</para>
/// <para>- src_layer (#mkldnn_query_src_md, 0)</para>
/// <para>- src_iter (#mkldnn_query_src_md, 1), if used</para>
/// <para>- src_iter_c (#mkldnn_query_src_md, 2), if used</para>
/// <para>- weights_layer (#mkldnn_query_weights_md, 0)</para>
/// <para>- weights_iter (#mkldnn_query_weights_md, 1)</para>
/// <para>- bias (#mkldnn_query_weights_md, 2), if used</para>
/// <para>- dst_layer (#mkldnn_query_dst_md, 0)</para>
/// <para>- dst_iter (#mkldnn_query_dst_md, 1), if used</para>
/// <para>- dst_iter_c (#mkldnn_query_dst_md, 2), if used</para>
/// <para>- diff_dst_layer (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- diff_dst_iter (#mkldnn_query_diff_dst_md, 1), if used</para>
/// <para>- diff_dst_iter_c (#mkldnn_query_diff_dst_md, 2), if used</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src_layer (#mkldnn_query_diff_src_md, 0)</para>
/// <para>- diff_src_iter (#mkldnn_query_diff_src_md, 1), if used</para>
/// <para>- diff_src_iter_c (#mkldnn_query_diff_src_md, 2), if used</para>
/// <para>- diff_weights_layer (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_weights_iter (#mkldnn_query_diff_weights_md, 1)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 2), if used</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnLstmBackwardDescInit(global::Intel.MklDnn.MkldnnRnnDescT rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::Intel.MklDnn.MkldnnMemoryDescT src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_c_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_c_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_iter_c_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_iter_c_desc, uint flags)
        {
            var __arg0 = ReferenceEquals(rnn_desc, null) ? global::System.IntPtr.Zero : rnn_desc.__Instance;
            var __arg3 = ReferenceEquals(src_layer_desc, null) ? global::System.IntPtr.Zero : src_layer_desc.__Instance;
            var __arg4 = ReferenceEquals(src_iter_desc, null) ? global::System.IntPtr.Zero : src_iter_desc.__Instance;
            var __arg5 = ReferenceEquals(src_iter_c_desc, null) ? global::System.IntPtr.Zero : src_iter_c_desc.__Instance;
            var __arg6 = ReferenceEquals(weights_layer_desc, null) ? global::System.IntPtr.Zero : weights_layer_desc.__Instance;
            var __arg7 = ReferenceEquals(weights_iter_desc, null) ? global::System.IntPtr.Zero : weights_iter_desc.__Instance;
            var __arg8 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg9 = ReferenceEquals(dst_layer_desc, null) ? global::System.IntPtr.Zero : dst_layer_desc.__Instance;
            var __arg10 = ReferenceEquals(dst_iter_desc, null) ? global::System.IntPtr.Zero : dst_iter_desc.__Instance;
            var __arg11 = ReferenceEquals(dst_iter_c_desc, null) ? global::System.IntPtr.Zero : dst_iter_c_desc.__Instance;
            var __arg12 = ReferenceEquals(diff_src_layer_desc, null) ? global::System.IntPtr.Zero : diff_src_layer_desc.__Instance;
            var __arg13 = ReferenceEquals(diff_src_iter_desc, null) ? global::System.IntPtr.Zero : diff_src_iter_desc.__Instance;
            var __arg14 = ReferenceEquals(diff_src_iter_c_desc, null) ? global::System.IntPtr.Zero : diff_src_iter_c_desc.__Instance;
            var __arg15 = ReferenceEquals(diff_weights_layer_desc, null) ? global::System.IntPtr.Zero : diff_weights_layer_desc.__Instance;
            var __arg16 = ReferenceEquals(diff_weights_iter_desc, null) ? global::System.IntPtr.Zero : diff_weights_iter_desc.__Instance;
            var __arg17 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg18 = ReferenceEquals(diff_dst_layer_desc, null) ? global::System.IntPtr.Zero : diff_dst_layer_desc.__Instance;
            var __arg19 = ReferenceEquals(diff_dst_iter_desc, null) ? global::System.IntPtr.Zero : diff_dst_iter_desc.__Instance;
            var __arg20 = ReferenceEquals(diff_dst_iter_c_desc, null) ? global::System.IntPtr.Zero : diff_dst_iter_c_desc.__Instance;
            var __ret = __Internal.MkldnnLstmBackwardDescInit(__arg0, prop_kind, direction, __arg3, __arg4, __arg5, __arg6, __arg7, __arg8, __arg9, __arg10, __arg11, __arg12, __arg13, __arg14, __arg15, __arg16, __arg17, __arg18, __arg19, __arg20, flags);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a GRU descriptorfor forward propagation</para>
/// <para>usingand memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>Ifequals #mkldnn_forward_training, you must query a</para>
/// <para>workspace memory descriptor before creating the primitive.</para>
/// <para>andare allowed to either be</para>
/// <para>or point to a zero memory descriptor, which would indicate that the</para>
/// <para>RNN primitive should not use them and will default to zero values.</para>
/// <para>All memory descriptors exceptare allowed to be</para>
/// <para>initialized with #mkldnn_format_kind_any value of</para>
/// <para>Parameters:</para>
/// <para>- flags (unused for now)</para>
/// <para>Inputs:</para>
/// <para>- src_layer (#mkldnn_query_src_md, 0)</para>
/// <para>- src_iter (#mkldnn_query_src_md, 1), if used</para>
/// <para>- weights_layer (#mkldnn_query_weights_md, 0)</para>
/// <para>- weights_iter (#mkldnn_query_weights_md, 1)</para>
/// <para>- bias (#mkldnn_query_weights_md, 2), if used</para>
/// <para>Outputs:</para>
/// <para>- dst_layer (#mkldnn_query_dst_md, 0)</para>
/// <para>- dst_iter (#mkldnn_query_dst_md, 1), if used</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>ifequals #mkldnn_forward_training</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnGruForwardDescInit(global::Intel.MklDnn.MkldnnRnnDescT rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::Intel.MklDnn.MkldnnMemoryDescT src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_desc, uint flags)
        {
            var __arg0 = ReferenceEquals(rnn_desc, null) ? global::System.IntPtr.Zero : rnn_desc.__Instance;
            var __arg3 = ReferenceEquals(src_layer_desc, null) ? global::System.IntPtr.Zero : src_layer_desc.__Instance;
            var __arg4 = ReferenceEquals(src_iter_desc, null) ? global::System.IntPtr.Zero : src_iter_desc.__Instance;
            var __arg5 = ReferenceEquals(weights_layer_desc, null) ? global::System.IntPtr.Zero : weights_layer_desc.__Instance;
            var __arg6 = ReferenceEquals(weights_iter_desc, null) ? global::System.IntPtr.Zero : weights_iter_desc.__Instance;
            var __arg7 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg8 = ReferenceEquals(dst_layer_desc, null) ? global::System.IntPtr.Zero : dst_layer_desc.__Instance;
            var __arg9 = ReferenceEquals(dst_iter_desc, null) ? global::System.IntPtr.Zero : dst_iter_desc.__Instance;
            var __ret = __Internal.MkldnnGruForwardDescInit(__arg0, prop_kind, direction, __arg3, __arg4, __arg5, __arg6, __arg7, __arg8, __arg9, flags);
            return __ret;
        }

        /// <summary>
/// <para>Initializes a GRU descriptorfor backward propagation</para>
/// <para>usingand memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>All memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>(simultaneously with(simultaneously withand</para>
/// <para>(simultaneously withare allowed to</para>
/// <para>either beor point to a zero memory descriptor, which would indicate</para>
/// <para>that the RNN primitive should not use them and will default to zero values.</para>
/// <para>Parameters:</para>
/// <para>- flags (unused for now)</para>
/// <para>Inputs:</para>
/// <para>- src_layer (#mkldnn_query_src_md, 0)</para>
/// <para>- src_iter (#mkldnn_query_src_md, 1), if used</para>
/// <para>- weights_layer (#mkldnn_query_weights_md, 0)</para>
/// <para>- weights_iter (#mkldnn_query_weights_md, 1)</para>
/// <para>- bias (#mkldnn_query_weights_md, 2), if used</para>
/// <para>- dst_layer (#mkldnn_query_dst_md, 0)</para>
/// <para>- dst_iter (#mkldnn_query_dst_md, 1), if used</para>
/// <para>- diff_dst_layer (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- diff_dst_iter (#mkldnn_query_diff_dst_md, 1), if used</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src_layer (#mkldnn_query_diff_src_md, 0)</para>
/// <para>- diff_src_iter (#mkldnn_query_diff_src_md, 1), if used</para>
/// <para>- diff_weights_layer (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_weights_iter (#mkldnn_query_diff_weights_md, 1)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 2), if used</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnGruBackwardDescInit(global::Intel.MklDnn.MkldnnRnnDescT rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::Intel.MklDnn.MkldnnMemoryDescT src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_iter_desc, uint flags)
        {
            var __arg0 = ReferenceEquals(rnn_desc, null) ? global::System.IntPtr.Zero : rnn_desc.__Instance;
            var __arg3 = ReferenceEquals(src_layer_desc, null) ? global::System.IntPtr.Zero : src_layer_desc.__Instance;
            var __arg4 = ReferenceEquals(src_iter_desc, null) ? global::System.IntPtr.Zero : src_iter_desc.__Instance;
            var __arg5 = ReferenceEquals(weights_layer_desc, null) ? global::System.IntPtr.Zero : weights_layer_desc.__Instance;
            var __arg6 = ReferenceEquals(weights_iter_desc, null) ? global::System.IntPtr.Zero : weights_iter_desc.__Instance;
            var __arg7 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg8 = ReferenceEquals(dst_layer_desc, null) ? global::System.IntPtr.Zero : dst_layer_desc.__Instance;
            var __arg9 = ReferenceEquals(dst_iter_desc, null) ? global::System.IntPtr.Zero : dst_iter_desc.__Instance;
            var __arg10 = ReferenceEquals(diff_src_layer_desc, null) ? global::System.IntPtr.Zero : diff_src_layer_desc.__Instance;
            var __arg11 = ReferenceEquals(diff_src_iter_desc, null) ? global::System.IntPtr.Zero : diff_src_iter_desc.__Instance;
            var __arg12 = ReferenceEquals(diff_weights_layer_desc, null) ? global::System.IntPtr.Zero : diff_weights_layer_desc.__Instance;
            var __arg13 = ReferenceEquals(diff_weights_iter_desc, null) ? global::System.IntPtr.Zero : diff_weights_iter_desc.__Instance;
            var __arg14 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg15 = ReferenceEquals(diff_dst_layer_desc, null) ? global::System.IntPtr.Zero : diff_dst_layer_desc.__Instance;
            var __arg16 = ReferenceEquals(diff_dst_iter_desc, null) ? global::System.IntPtr.Zero : diff_dst_iter_desc.__Instance;
            var __ret = __Internal.MkldnnGruBackwardDescInit(__arg0, prop_kind, direction, __arg3, __arg4, __arg5, __arg6, __arg7, __arg8, __arg9, __arg10, __arg11, __arg12, __arg13, __arg14, __arg15, __arg16, flags);
            return __ret;
        }

        /// <summary>
/// <para>Initializes an LBR GRU descriptorfor forward propagation</para>
/// <para>usingand memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>Ifequals #mkldnn_forward_training, you must query a</para>
/// <para>workspace memory descriptor before creating the primitive.</para>
/// <para>andare allowed to either be</para>
/// <para>or point to a zero memory descriptor, which would indicate that the</para>
/// <para>RNN primitive should not use them and will default to zero values.</para>
/// <para>All memory descriptors exceptare allowed to be</para>
/// <para>initialized with #mkldnn_format_kind_any value of</para>
/// <para>Parameters:</para>
/// <para>- flags (unused for now)</para>
/// <para>Inputs:</para>
/// <para>- src_layer (#mkldnn_query_src_md, 0)</para>
/// <para>- src_iter (#mkldnn_query_src_md, 1), if used</para>
/// <para>- weights_layer (#mkldnn_query_weights_md, 0)</para>
/// <para>- weights_iter (#mkldnn_query_weights_md, 1)</para>
/// <para>- bias (#mkldnn_query_weights_md, 2), if used</para>
/// <para>Outputs:</para>
/// <para>- dst_layer (#mkldnn_query_dst_md, 0)</para>
/// <para>- dst_iter (#mkldnn_query_dst_md, 1), if used</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0),</para>
/// <para>ifequals #mkldnn_forward_training</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnLbrGruForwardDescInit(global::Intel.MklDnn.MkldnnRnnDescT rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::Intel.MklDnn.MkldnnMemoryDescT src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_desc, uint flags)
        {
            var __arg0 = ReferenceEquals(rnn_desc, null) ? global::System.IntPtr.Zero : rnn_desc.__Instance;
            var __arg3 = ReferenceEquals(src_layer_desc, null) ? global::System.IntPtr.Zero : src_layer_desc.__Instance;
            var __arg4 = ReferenceEquals(src_iter_desc, null) ? global::System.IntPtr.Zero : src_iter_desc.__Instance;
            var __arg5 = ReferenceEquals(weights_layer_desc, null) ? global::System.IntPtr.Zero : weights_layer_desc.__Instance;
            var __arg6 = ReferenceEquals(weights_iter_desc, null) ? global::System.IntPtr.Zero : weights_iter_desc.__Instance;
            var __arg7 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg8 = ReferenceEquals(dst_layer_desc, null) ? global::System.IntPtr.Zero : dst_layer_desc.__Instance;
            var __arg9 = ReferenceEquals(dst_iter_desc, null) ? global::System.IntPtr.Zero : dst_iter_desc.__Instance;
            var __ret = __Internal.MkldnnLbrGruForwardDescInit(__arg0, prop_kind, direction, __arg3, __arg4, __arg5, __arg6, __arg7, __arg8, __arg9, flags);
            return __ret;
        }

        /// <summary>
/// <para>Initializes an LBR GRU descriptorfor backward propagation</para>
/// <para>usingand memory descriptors.</para>
/// </summary>
/// <remarks>
/// <para>All memory descriptors are allowed to be initialized with</para>
/// <para>#mkldnn_format_kind_any value of</para>
/// <para>(simultaneously with(simultaneously withand</para>
/// <para>(simultaneously withare allowed to</para>
/// <para>either beor point to a zero memory descriptor, which would indicate</para>
/// <para>that the RNN primitive should not use them and will default to zero values.</para>
/// <para>Parameters:</para>
/// <para>- flags (unused for now)</para>
/// <para>Inputs:</para>
/// <para>- src_layer (#mkldnn_query_src_md, 0)</para>
/// <para>- src_iter (#mkldnn_query_src_md, 1), if used</para>
/// <para>- weights_layer (#mkldnn_query_weights_md, 0)</para>
/// <para>- weights_iter (#mkldnn_query_weights_md, 1)</para>
/// <para>- bias (#mkldnn_query_weights_md, 2), if used</para>
/// <para>- dst_layer (#mkldnn_query_dst_md, 0)</para>
/// <para>- dst_iter (#mkldnn_query_dst_md, 1), if used</para>
/// <para>- diff_dst_layer (#mkldnn_query_diff_dst_md, 0)</para>
/// <para>- diff_dst_iter (#mkldnn_query_diff_dst_md, 1), if used</para>
/// <para>- workspace (#mkldnn_query_workspace_md, 0)</para>
/// <para>Outputs:</para>
/// <para>- diff_src_layer (#mkldnn_query_diff_src_md, 0)</para>
/// <para>- diff_src_iter (#mkldnn_query_diff_src_md, 1), if used</para>
/// <para>- diff_weights_layer (#mkldnn_query_diff_weights_md, 0)</para>
/// <para>- diff_weights_iter (#mkldnn_query_diff_weights_md, 1)</para>
/// <para>- diff_bias (#mkldnn_query_diff_weights_md, 2), if used</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnLbrGruBackwardDescInit(global::Intel.MklDnn.MkldnnRnnDescT rnn_desc, global::Intel.MklDnn.MkldnnPropKindT prop_kind, global::Intel.MklDnn.MkldnnRnnDirectionT direction, global::Intel.MklDnn.MkldnnMemoryDescT src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT dst_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_src_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_weights_iter_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_bias_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_layer_desc, global::Intel.MklDnn.MkldnnMemoryDescT diff_dst_iter_desc, uint flags)
        {
            var __arg0 = ReferenceEquals(rnn_desc, null) ? global::System.IntPtr.Zero : rnn_desc.__Instance;
            var __arg3 = ReferenceEquals(src_layer_desc, null) ? global::System.IntPtr.Zero : src_layer_desc.__Instance;
            var __arg4 = ReferenceEquals(src_iter_desc, null) ? global::System.IntPtr.Zero : src_iter_desc.__Instance;
            var __arg5 = ReferenceEquals(weights_layer_desc, null) ? global::System.IntPtr.Zero : weights_layer_desc.__Instance;
            var __arg6 = ReferenceEquals(weights_iter_desc, null) ? global::System.IntPtr.Zero : weights_iter_desc.__Instance;
            var __arg7 = ReferenceEquals(bias_desc, null) ? global::System.IntPtr.Zero : bias_desc.__Instance;
            var __arg8 = ReferenceEquals(dst_layer_desc, null) ? global::System.IntPtr.Zero : dst_layer_desc.__Instance;
            var __arg9 = ReferenceEquals(dst_iter_desc, null) ? global::System.IntPtr.Zero : dst_iter_desc.__Instance;
            var __arg10 = ReferenceEquals(diff_src_layer_desc, null) ? global::System.IntPtr.Zero : diff_src_layer_desc.__Instance;
            var __arg11 = ReferenceEquals(diff_src_iter_desc, null) ? global::System.IntPtr.Zero : diff_src_iter_desc.__Instance;
            var __arg12 = ReferenceEquals(diff_weights_layer_desc, null) ? global::System.IntPtr.Zero : diff_weights_layer_desc.__Instance;
            var __arg13 = ReferenceEquals(diff_weights_iter_desc, null) ? global::System.IntPtr.Zero : diff_weights_iter_desc.__Instance;
            var __arg14 = ReferenceEquals(diff_bias_desc, null) ? global::System.IntPtr.Zero : diff_bias_desc.__Instance;
            var __arg15 = ReferenceEquals(diff_dst_layer_desc, null) ? global::System.IntPtr.Zero : diff_dst_layer_desc.__Instance;
            var __arg16 = ReferenceEquals(diff_dst_iter_desc, null) ? global::System.IntPtr.Zero : diff_dst_iter_desc.__Instance;
            var __ret = __Internal.MkldnnLbrGruBackwardDescInit(__arg0, prop_kind, direction, __arg3, __arg4, __arg5, __arg6, __arg7, __arg8, __arg9, __arg10, __arg11, __arg12, __arg13, __arg14, __arg15, __arg16, flags);
            return __ret;
        }

        /// <summary>Returns the number of engines of a particular</summary>
        public static ulong MkldnnEngineGetCount(global::Intel.MklDnn.MkldnnEngineKindT kind)
        {
            var __ret = __Internal.MkldnnEngineGetCount(kind);
            return __ret;
        }

        /// <summary>Creates anof particularand</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnEngineCreate(global::Intel.MklDnn.MkldnnEngine engine, global::Intel.MklDnn.MkldnnEngineKindT kind, ulong index)
        {
            var ____arg0 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __ret = __Internal.MkldnnEngineCreate(__arg0, kind, index);
            return __ret;
        }

        /// <summary>Returns the kind of an</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnEngineGetKind(global::Intel.MklDnn.MkldnnEngine engine, global::Intel.MklDnn.MkldnnEngineKindT* kind)
        {
            var __arg0 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __ret = __Internal.MkldnnEngineGetKind(__arg0, kind);
            return __ret;
        }

        /// <summary>Destroys an</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnEngineDestroy(global::Intel.MklDnn.MkldnnEngine engine)
        {
            var __arg0 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __ret = __Internal.MkldnnEngineDestroy(__arg0);
            return __ret;
        }

        /// <summary>Creates an executionforand with</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnStreamCreate(global::Intel.MklDnn.MkldnnStream stream, global::Intel.MklDnn.MkldnnEngine engine, uint flags)
        {
            var ____arg0 = ReferenceEquals(stream, null) ? global::System.IntPtr.Zero : stream.__Instance;
            var __arg0 = new global::System.IntPtr(&____arg0);
            var __arg1 = ReferenceEquals(engine, null) ? global::System.IntPtr.Zero : engine.__Instance;
            var __ret = __Internal.MkldnnStreamCreate(__arg0, __arg1, flags);
            return __ret;
        }

        /// <summary>Waits for all primitives in the executionto finish.</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnStreamWait(global::Intel.MklDnn.MkldnnStream stream)
        {
            var __arg0 = ReferenceEquals(stream, null) ? global::System.IntPtr.Zero : stream.__Instance;
            var __ret = __Internal.MkldnnStreamWait(__arg0);
            return __ret;
        }

        /// <summary>Destroys an execution</summary>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnStreamDestroy(global::Intel.MklDnn.MkldnnStream stream)
        {
            var __arg0 = ReferenceEquals(stream, null) ? global::System.IntPtr.Zero : stream.__Instance;
            var __ret = __Internal.MkldnnStreamDestroy(__arg0);
            return __ret;
        }

        /// <summary>
/// <para>Sets verbosity level (print information to stdout).</para>
/// <para>Possible levels are:</para>
/// <para>- 0 -- no verbose output (default)</para>
/// <para>- 1 -- primitive information at execution</para>
/// <para>- 2 -- primitive information at creation and execution</para>
/// </summary>
/// <remarks>
/// <para>Dumping information might affect performance.</para>
/// <para>This setting overrides the MKLDNN_VERBOSE environment variable.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnSetVerbose(int level)
        {
            var __ret = __Internal.MkldnnSetVerbose(level);
            return __ret;
        }

        /// <summary>
/// <para>Enables or disables dumping of JIT-generated code.</para>
/// <para>The enable parameter can be:</para>
/// <para>- 0 -- disable</para>
/// <para>- any other value -- enable</para>
/// </summary>
/// <remarks>This setting overrides the MKLDNN_JIT_DUMP environment variable.</remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnSetJitDump(int enable)
        {
            var __ret = __Internal.MkldnnSetJitDump(enable);
            return __ret;
        }

        /// <summary>
/// <para>Gets library version information.</para>
/// <para>Version information includes:</para>
/// <para>- major -- major version number</para>
/// <para>- minor -- minor version number</para>
/// <para>- patch -- patch release number</para>
/// <para>- hash -- git commit hash</para>
/// </summary>
        public static global::Intel.MklDnn.MkldnnVersionT MkldnnVersion()
        {
            var __ret = __Internal.MkldnnVersion();
            global::Intel.MklDnn.MkldnnVersionT __result0;
            if (__ret == IntPtr.Zero) __result0 = null;
            else if (global::Intel.MklDnn.MkldnnVersionT.NativeToManagedMap.ContainsKey(__ret))
                __result0 = (global::Intel.MklDnn.MkldnnVersionT) global::Intel.MklDnn.MkldnnVersionT.NativeToManagedMap[__ret];
            else __result0 = global::Intel.MklDnn.MkldnnVersionT.__CreateInstance(__ret);
            return __result0;
        }

        /// <summary>SGEMM performs a matrix-matrix multiplication operation defined as</summary>
/// <remarks>
/// <para>C := alpha*op( A )*op( B ) + beta*C</para>
/// <para>where</para>
/// <para>- op( X ) is one of op( X ) = X or op( X ) = X**T,</para>
/// <para>- alpha and beta are scalars,</para>
/// <para>- A, B and C are matrices, with op( A ) an m by k matrix, op( B ) a k by n matrix</para>
/// <para>and C an m by n matrix.</para>
/// <para>The matrices are assumed to be stored in row-major order (the elements</para>
/// <para>in a matrix rows are contiguous in memory).</para>
/// <para>The API is different from the standard BLAS routine</para>
/// <para>because it returns mkldnn_status_t for error handling.</para>
/// <para>XERBLA is not supported: no error message will be printed</para>
/// <para>in case of incorrect parameters.</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnSgemm(sbyte transa, sbyte transb, long M, long N, long K, float alpha, ref float A, long lda, ref float B, long ldb, float beta, ref float C, long ldc)
        {
            fixed (float* __A6 = &A)
            {
                var __arg6 = __A6;
                fixed (float* __B8 = &B)
                {
                    var __arg8 = __B8;
                    fixed (float* __C11 = &C)
                    {
                        var __arg11 = __C11;
                        var __ret = __Internal.MkldnnSgemm(transa, transb, M, N, K, alpha, __arg6, lda, __arg8, ldb, beta, __arg11, ldc);
                        return __ret;
                    }
                }
            }
        }

        /// <summary>
/// <para>gemm_s8u8s32 and gemm_s8s8s32 perform a matrix-matrix multiplication</para>
/// <para>operation and add the result to a scalar-matrix product. For the final</para>
/// <para>result, a vector is added to each row or column of the output matrix.</para>
/// <para>The operation is defined as:</para>
/// </summary>
/// <remarks>
/// <para>C := alpha*(op(A) - A_offset) * (op(B) - B_offset) + beta*C + C_offset</para>
/// <para>where</para>
/// <para>- op( X ) = X or op( X ) = X**T,</para>
/// <para>- A_offset is an m-by-k matrix with every element equal to the value oa,</para>
/// <para>- B_offset is an k-by-n matrix with every element equal to the value ob,</para>
/// <para>- C_offset is an m-by-n matrix defined by the oc array, size len:</para>
/// <para>- if offsetc = F: len must be at least 1</para>
/// <para>- if offsetc = C: len must be at least max(1, m)</para>
/// <para>- if offsetc = R: len must be at least max(1, n)</para>
/// <para>- alpha and beta are scalars, and A, B and C are matrices, with op( A )</para>
/// <para>an m-by-k matrix, op( B ) a k-by-n matrix and C an m-by-n matrix.</para>
/// <para>The matrices are assumed to be stored in column-major order (the elements</para>
/// <para>in a matrix columns are contiguous in memory).</para>
/// <para>The API is different compared with the standard BLAS routine</para>
/// <para>because it returns mkldnn_status_t for error handling.</para>
/// <para>XERBLA is not supported: no error message will be printed</para>
/// <para>in case of incorrect parameters.</para>
/// <para>On some architectures the intermediate saturation might happen,</para>
/// <para>which would lead to unexpected results. For more details, refer to</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnGemmU8s8s32(sbyte transa, sbyte transb, sbyte offsetc, long M, long N, long K, float alpha, byte* A, long lda, byte ao, sbyte* B, long ldb, sbyte bo, float beta, ref int C, long ldc, ref int co)
        {
            fixed (int* __C14 = &C)
            {
                var __arg14 = __C14;
                fixed (int* __co16 = &co)
                {
                    var __arg16 = __co16;
                    var __ret = __Internal.MkldnnGemmU8s8s32(transa, transb, offsetc, M, N, K, alpha, A, lda, ao, B, ldb, bo, beta, __arg14, ldc, __arg16);
                    return __ret;
                }
            }
        }

        /// <summary>
/// <para>gemm_s8u8s32 and gemm_s8s8s32 perform a matrix-matrix multiplication</para>
/// <para>operation and add the result to a scalar-matrix product. For the final</para>
/// <para>result, a vector is added to each row or column of the output matrix.</para>
/// </summary>
/// <remarks>
/// <para>For full description, see mkldnn_gemm_u8s8s32().</para>
/// <para>dev_guide_int8_computations</para>
/// </remarks>
        public static global::Intel.MklDnn.MkldnnStatusT MkldnnGemmS8s8s32(sbyte transa, sbyte transb, sbyte offsetc, long M, long N, long K, float alpha, sbyte* A, long lda, sbyte ao, sbyte* B, long ldb, sbyte bo, float beta, ref int C, long ldc, ref int co)
        {
            fixed (int* __C14 = &C)
            {
                var __arg14 = __C14;
                fixed (int* __co16 = &co)
                {
                    var __arg16 = __co16;
                    var __ret = __Internal.MkldnnGemmS8s8s32(transa, transb, offsetc, M, N, K, alpha, A, lda, ao, B, ldb, bo, beta, __arg14, ldc, __arg16);
                    return __ret;
                }
            }
        }
    }

    /// <summary>Status values returned by the library functions.</summary>
    public enum MkldnnStatusT
    {
        /// <summary>The operation was successful</summary>
        MkldnnSuccess = 0,
        /// <summary>The operation failed due to an out-of-memory condition</summary>
        MkldnnOutOfMemory = 1,
        /// <summary>The operation failed because of incorrect function arguments</summary>
        MkldnnInvalidArguments = 2,
        /// <summary>The operation failed because requested functionality is not implemented</summary>
        MkldnnUnimplemented = 3,
        /// <summary>Primitive iterator passed over last primitive descriptor</summary>
        MkldnnIteratorEnds = 4,
        /// <summary>Primitive or engine failed on execution</summary>
        MkldnnRuntimeError = 5,
        /// <summary>Queried element is not required for given primitive</summary>
        MkldnnNotRequired = 6
    }

    /// <summary>Data type specification</summary>
    public enum MkldnnDataTypeT
    {
        /// <summary>Undefined data type, used for empty memory descriptors.</summary>
        MkldnnDataTypeUndef = 0,
        /// <summary>16-bit/half-precision floating point.</summary>
        MkldnnF16 = 1,
        /// <summary>non-standard 16-bit (bfloat16 w/ 7 bit mantissa) floating point.</summary>
        MkldnnBf16 = 2,
        /// <summary>32-bit/single-precision floating point.</summary>
        MkldnnF32 = 3,
        /// <summary>32-bit signed integer.</summary>
        MkldnnS32 = 4,
        /// <summary>8-bit signed integer.</summary>
        MkldnnS8 = 5,
        /// <summary>8-bit unsigned integer.</summary>
        MkldnnU8 = 6
    }

    /// <summary>Memory format kind</summary>
    public enum MkldnnFormatKindT
    {
        /// <summary>Undefined memory format kind, used for empty memory descriptors.</summary>
        MkldnnFormatKindUndef = 0,
        /// <summary>
/// <para>Unspecified format kind.</para>
/// <para>The primitive selects a format automatically.</para>
/// </summary>
        MkldnnFormatKindAny = 1,
        /// <summary>
/// <para>A tensor in a generic format described by the stride and blocking</para>
/// <para>values in each dimension. See</para>
/// </summary>
/// <remarks>information.</remarks>
        MkldnnBlocked = 2,
        /// <summary>Weights format used in 8bit Winograd convolution</summary>
        MkldnnFormatKindWino = 3,
        /// <summary>Packed weights format used in RNN</summary>
        MkldnnFormatKindRnnPacked = 4
    }

    /// <summary>Memory format tag specification.</summary>
/// <remarks>
/// <para>Intel MKL-DNN formats describe physical data layout. The physical layout</para>
/// <para>is described as a sequence of the dimensions as they are laid out in the</para>
/// <para>memory (from the outer-most to the inner-most). Note that this order</para>
/// <para>doesn't affect the logical order of the dimensions that is kept in the</para>
/// <para>`dims` field of the mkldnn_memory_desc_t structure. The logical order of the</para>
/// <para>dimensions is specified by the primitive that uses the tensor.</para>
/// <para>For example, CNN 5D tensor always has its logical dimensions in the order</para>
/// <para>`(batch, channels, depth, height, width)`, while the physical layout might be</para>
/// <para>`NCDHW` (corresponds to #mkldnn_ncdhw format tag) or</para>
/// <para>`NDHWC` (corresponds to #mkldnn_ndhwc format tag).</para>
/// <para>~~~cpp</para>
/// <para>int batch = 2, channels = 16, depth = 13, height = 13, width = 13;</para>
/// <para>int ndims = 5; // 5D tensor</para>
/// <para>mkldnn_dims_t dims = {batch, channels, depth, height, width};</para>
/// <para>mkldnn_memory_desc_t data_in_ncdhw;</para>
/// <para>mkldnn_memory_desc_init_by_tag(</para>
/// <para>&amp;data_in_ncdhw, 5, dims, mkldnn_f32, mkldnn_ncdhw);</para>
/// <para>// note that in both cases dims passed are the same</para>
/// <para>mkldnn_memory_desc_t data_in_ndhwc;</para>
/// <para>mkldnn_memory_desc_init_by_tag(</para>
/// <para>&amp;data_in_ndhwc, 5, dims, mkldnn_f32, mkldnn_ndhwc);</para>
/// <para>~~~</para>
/// <para>Memory format tags can be further divided into two categories:</para>
/// <para>- Domain-agnostic names, i.e. names the do not depend on the tensor usage</para>
/// <para>in the specific primitive. These names use letters from `a` to `l` to</para>
/// <para>denote logical dimension from 1 to 12, and form the order in which the</para>
/// <para>dimensions are laid in memory. For instance, #mkldnn_ab is used to denote</para>
/// <para>2D tensor where the second logical dimension (aka `b`) is the innermost,</para>
/// <para>i.e. has stride = 1, and the first logical dimension (`a`) laid out in</para>
/// <para>memory with stride equal to the size of second dimension. On the other</para>
/// <para>hand, #mkldnn_ba is just transposed version of the same tensor: the</para>
/// <para>first dimension (`a`) becomes the innermost one.</para>
/// <para>- Domain-specific names, i.e. names that make sense only in the context of</para>
/// <para>a certain domain, such as CNN. This names are just aliases to the</para>
/// <para>corresponding domain-agnostic tags and used mostly for the convenience.</para>
/// <para>For example, #mkldnn_nc is used to denote 2D CNN activations tensor</para>
/// <para>memory format, where channels are the innermost dimension and batch is an</para>
/// <para>outermost one. Moreover, #mkldnn_nc is just an alias to #mkldnn_ab,</para>
/// <para>since for Intel MKL-DNN CNN primitives the logical dimensions of</para>
/// <para>activations tensors come in order: batch, channels, spatial.</para>
/// <para>In other words, batch corresponds to the first logical dimension (`a`),</para>
/// <para>channels correspond to the second one (`b`).</para>
/// <para>The following domain-specific notation applies to memory format tags:</para>
/// <para>-denotes the mini-batch dimension</para>
/// <para>-denotes a channels dimension</para>
/// <para>- When there are multiple channel dimensions (for example, in convolution</para>
/// <para>weights tensor),anddenote dimensions of input and output</para>
/// <para>channels</para>
/// <para>-anddenote spatial depth, height, and width</para>
/// <para>respectively</para>
/// <para>Upper-case letters indicate that the data is laid out in blocks for a</para>
/// <para>particular dimension. In such cases, the format name contains both upper-</para>
/// <para>and lower-case letters for that dimension with a lower-case letter preceded</para>
/// <para>by the block size. For example: #mkldnn_nChw8c describes a format where the</para>
/// <para>outermost dimension is mini-batch, followed by the channel block number,</para>
/// <para>followed by the spatial height and width, and finally followed by 8-element</para>
/// <para>channel blocks.</para>
/// </remarks>
    public enum MkldnnFormatTagT
    {
        /// <summary>Undefined memory format tag</summary>
        MkldnnFormatTagUndef = 0,
        /// <summary>
/// <para>Undefined memory format tag.</para>
/// <para>The primitive selects a format automatically.</para>
/// </summary>
        MkldnnFormatTagAny = 1,
        /// <summary>plain 1D tensor</summary>
        MkldnnA = 2,
        /// <summary>plain 2D tensor</summary>
        MkldnnAb = 3,
        /// <summary>plain 3D tensor</summary>
        MkldnnAbc = 4,
        /// <summary>plain 4D tensor</summary>
        MkldnnAbcd = 5,
        /// <summary>plain 5D tensor</summary>
        MkldnnAbcde = 6,
        /// <summary>plain 6D tensor</summary>
        MkldnnAbcdef = 7,
        /// <summary>permuted 5D tensor</summary>
        MkldnnAbdec = 8,
        /// <summary>permuted 3D tensor</summary>
        MkldnnAcb = 9,
        /// <summary>permuted 5D tensor</summary>
        MkldnnAcbde = 10,
        /// <summary>permuted 4D tensor</summary>
        MkldnnAcdb = 11,
        /// <summary>permuted 5D tensor</summary>
        MkldnnAcdeb = 12,
        /// <summary>permuted 2D tensor</summary>
        MkldnnBa = 13,
        /// <summary>permuted 3D tensor</summary>
        MkldnnBac = 14,
        /// <summary>permuted 4D tensor</summary>
        MkldnnBacd = 15,
        /// <summary>permuted 3D tensor</summary>
        MkldnnBca = 16,
        /// <summary>permuted 4D tensor</summary>
        MkldnnBcda = 17,
        /// <summary>permuted 5D tensor</summary>
        MkldnnBcdea = 18,
        /// <summary>permuted 3D tensor</summary>
        MkldnnCba = 19,
        /// <summary>permuted 4D tensor</summary>
        MkldnnCdba = 20,
        /// <summary>permuted 5D tensor</summary>
        MkldnnCdeba = 21,
        /// <summary>permuted 5D tensor</summary>
        MkldnnDecab = 22,
        MkldnnAbc16a = 23,
        MkldnnABc16a16b = 24,
        /// <summary>3D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABc16b = 25,
        /// <summary>3D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABc16b16a = 26,
        /// <summary>3D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnAbc4a = 27,
        /// <summary>3D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABc4b = 28,
        /// <summary>3D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABc4b16a4b = 29,
        /// <summary>3D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABc4b4a = 30,
        /// <summary>3D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABc8a16b2a = 31,
        /// <summary>3D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABc8a8b = 32,
        /// <summary>3D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABc8b = 33,
        /// <summary>3D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABc8b16a2b = 34,
        /// <summary>3D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnBAc8a16b2a = 35,
        /// <summary>3D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABc8b8a = 36,
        /// <summary>3D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnAbcd16a = 37,
        /// <summary>3D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcd16a16b = 38,
        /// <summary>3D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcd32a32b = 39,
        /// <summary>4D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABcd16b = 40,
        /// <summary>4D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABcd16b16a = 41,
        /// <summary>4D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABCd16b16c = 42,
        /// <summary>4D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABCd16c16b = 43,
        /// <summary>4D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnAbcd4a = 44,
        /// <summary>4D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcd4b = 45,
        /// <summary>4D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcd4b16a4b = 46,
        /// <summary>4D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcd4b4a = 47,
        /// <summary>4D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCd4c16b4c = 48,
        /// <summary>4D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCd4c4b = 49,
        /// <summary>4D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcd8a16b2a = 50,
        /// <summary>4D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcd8a8b = 51,
        /// <summary>4D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcd8b = 52,
        /// <summary>4D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcd8b16a2b = 53,
        /// <summary>4D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABCd8b16c2b = 54,
        /// <summary>4D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnBAcd8a16b2a = 55,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnABcd8b8a = 56,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnABCd8b8c = 57,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnABCd8c16b2c = 58,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnABcde8a16b2a = 59,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnACBd8b16c2b = 60,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnABCd8c8b = 61,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnAbcde16a = 62,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnABcde16a16b = 63,
        /// <summary>4D tensor blocked by 1st and 2nd dimension with block size 8</summary>
        MkldnnBAcde8a16b2a = 64,
        /// <summary>5D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABcde16b = 65,
        /// <summary>5D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABcde16b16a = 66,
        /// <summary>5D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABCde16b16c = 67,
        /// <summary>5D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABCde16c16b = 68,
        /// <summary>5D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABCde2c8b4c = 69,
        /// <summary>5D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnAbcde4a = 70,
        /// <summary>5D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcde4b = 71,
        /// <summary>5D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcde4b4a = 72,
        /// <summary>5D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCde4b4c = 73,
        /// <summary>5D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCde4c16b4c = 74,
        /// <summary>5D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCde4c4b = 75,
        /// <summary>5D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAbcde8a = 76,
        /// <summary>5D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcde8a8b = 77,
        /// <summary>5D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnBAcde16b16a = 78,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcde8b = 79,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcde8b16a2b = 80,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABCde8b16c2b = 81,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnACBde8b16c2b = 82,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcde8b8a = 83,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABCde8b8c = 84,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcd4a8b8a4b = 85,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABcd2a8b8a2b = 86,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABCde4b8c8b4c = 87,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABCde2b8c8b2c = 88,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABCde8c16b2c = 89,
        /// <summary>5D tensor blocked by 2nd dimension with block size 8</summary>
        MkldnnABCde8c8b = 90,
        /// <summary>6D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABcdef16b = 91,
        /// <summary>6D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABCdef16b16c = 92,
        /// <summary>6D tensor blocked by 2nd dimension with block size 16</summary>
        MkldnnABCdef16c16b = 93,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABcdef4b = 94,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCdef4c4b = 95,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCdef8b8c = 96,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCdef8c16b2c = 97,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCdef8b16c2b = 98,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnACBdef8b16c2b = 99,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABCdef8c8b = 100,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdc16b = 101,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdc4b = 102,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdc8b = 103,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdec16b = 104,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdec32b = 105,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdec4b = 106,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdec8b = 107,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdefc16b = 108,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnACBdef16c16b = 109,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdefc4b = 110,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnABdefc8b = 111,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAbcdef16a = 112,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcb16a = 113,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcb4a = 114,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcb8a = 115,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnACBd16b16c = 116,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnACBd16c16b = 117,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnACBde16b16c = 118,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnACBde16c16b = 119,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcdb16a = 120,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcdb32a = 121,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcdb4a = 122,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcdb8a = 123,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcdeb16a = 124,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcdeb4a = 125,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnAcdeb8a = 126,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnBAc16a16b = 127,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnBAc16b16a = 128,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnBAcd16a16b = 129,
        /// <summary>6D tensor blocked by 2nd dimension with block size 4</summary>
        MkldnnBAcd16b16a = 130,
        /// <summary>
/// <para>Just a sentinel, not real memory format tag. Must be changed after new</para>
/// <para>format tag is added.</para>
/// </summary>
        MkldnnFormatTagLast = 131,
        /// <summary>1D tensor, an alias to #mkldnn_a</summary>
        MkldnnX = 2,
        /// <summary>2D CNN activations tensor, an alias to #mkldnn_ab</summary>
        MkldnnNc = 3,
        /// <summary>2D CNN activations tensor, an alias to #mkldnn_ba</summary>
        MkldnnCn = 13,
        /// <summary>3D CNN activations tensor, an alias to #mkldnn_abc</summary>
        MkldnnNcw = 4,
        /// <summary>3D CNN activations tensor, an alias to #mkldnn_acb</summary>
        MkldnnNwc = 9,
        /// <summary>4D CNN activations tensor, an alias to #mkldnn_abcd</summary>
        MkldnnNchw = 5,
        /// <summary>4D CNN activations tensor, an alias to #mkldnn_acdb</summary>
        MkldnnNhwc = 11,
        /// <summary>4D CNN activations tensor, an alias to #mkldnn_bcda</summary>
        MkldnnChwn = 17,
        /// <summary>5D CNN activations tensor, an alias to #mkldnn_abcde</summary>
        MkldnnNcdhw = 6,
        /// <summary>5D CNN activations tensor, an alias to #mkldnn_acdeb</summary>
        MkldnnNdhwc = 12,
        /// <summary>2D CNN weights tensor, an alias to #mkldnn_ab</summary>
        MkldnnOi = 3,
        /// <summary>2D CNN weights tensor, an alias to #mkldnn_ba</summary>
        MkldnnIo = 13,
        /// <summary>3D CNN weights tensor, an alias to #mkldnn_abc</summary>
        MkldnnOiw = 4,
        /// <summary>3D CNN weights tensor, an alias to #mkldnn_acb</summary>
        MkldnnOwi = 9,
        /// <summary>3D CNN weights tensor, an alias to #mkldnn_cba</summary>
        MkldnnWio = 19,
        /// <summary>3D CNN weights tensor, an alias to #mkldnn_bca</summary>
        MkldnnIwo = 16,
        /// <summary>4D CNN weights tensor, an alias to #mkldnn_abcd</summary>
        MkldnnOihw = 5,
        /// <summary>4D CNN weights tensor, an alias to #mkldnn_cdba</summary>
        MkldnnHwio = 20,
        /// <summary>4D CNN weights tensor, an alias to #mkldnn_acdb</summary>
        MkldnnOhwi = 11,
        /// <summary>4D CNN weights tensor, an alias to #mkldnn_bcda</summary>
        MkldnnIhwo = 17,
        /// <summary>4D CNN weights tensor, an alias to #mkldnn_bacd</summary>
        MkldnnIohw = 15,
        /// <summary>5D CNN weights tensor, an alias to #mkldnn_abcde</summary>
        MkldnnOidhw = 6,
        /// <summary>5D CNN weights tensor, an alias to #mkldnn_cdeba</summary>
        MkldnnDhwio = 21,
        /// <summary>5D CNN weights tensor, an alias to #mkldnn_acdeb</summary>
        MkldnnOdhwi = 12,
        /// <summary>5D CNN weights tensor, an alias to #mkldnn_bcdea</summary>
        MkldnnIdhwo = 18,
        /// <summary>4D CNN weights tensor (incl. groups), an alias to #mkldnn_abcd</summary>
        MkldnnGoiw = 5,
        /// <summary>5D CNN weights tensor (incl. groups), an alias to #mkldnn_abcde</summary>
        MkldnnGoihw = 6,
        /// <summary>5D CNN weights tensor (incl. groups), an alias to #mkldnn_decab</summary>
        MkldnnHwigo = 22,
        /// <summary>5D CNN weights tensor (incl. groups), an alias to #mkldnn_acbde</summary>
        MkldnnGiohw = 10,
        /// <summary>6D CNN weights tensor (incl. groups), an alias to #mkldnn_abcdef</summary>
        MkldnnGoidhw = 7,
        /// <summary>3D RNN data tensor in the format (seq_length, batch, input channels).</summary>
        MkldnnTnc = 4,
        /// <summary>3D RNN data tensor in the format (batch, seq_length, input channels).</summary>
        MkldnnNtc = 14,
        /// <summary>
/// <para>4D RNN states tensor in the format (num_layers, num_directions,</para>
/// <para>batch, state channels).</para>
/// </summary>
        MkldnnLdnc = 5,
        /// <summary>
/// <para>5D RNN weights tensor in the format (num_layers, num_directions,</para>
/// <para>input_channels, num_gates, output_channels).</para>
/// </summary>
/// <remarks>
/// <para>- For LSTM cells, the gates order is input, forget, candidate</para>
/// <para>and output gate.</para>
/// <para>- For GRU cells, the gates order is update, reset and output gate.</para>
/// </remarks>
        MkldnnLdigo = 6,
        /// <summary>
/// <para>5D RNN weights tensor in the format (num_layers, num_directions,</para>
/// <para>num_gates, output_channels, input_channels).</para>
/// </summary>
/// <remarks>
/// <para>- For LSTM cells, the gates order is input, forget, candidate</para>
/// <para>and output gate.</para>
/// <para>- For GRU cells, the gates order is update, reset and output gate.</para>
/// </remarks>
        MkldnnLdgoi = 8,
        /// <summary>
/// <para>4D RNN bias tensor in the format (num_layers, num_directions,</para>
/// <para>num_gates, output_channels).</para>
/// </summary>
/// <remarks>
/// <para>- For LSTM cells, the gates order is input, forget, candidate</para>
/// <para>and output gate.</para>
/// <para>- For GRU cells, the gates order is update, reset and output gate.</para>
/// </remarks>
        MkldnnLdgo = 5,
        /// <summary>
/// <para>5D CNN activations tensor blocked by channels with block size 16,</para>
/// <para>an alias to #mkldnn_aBcde16b</para>
/// </summary>
        MkldnnNCdhw16c = 65,
        /// <summary>
/// <para>5D CNN activations tensor blocked by channels with block size 4,</para>
/// <para>an alias to #mkldnn_aBcde4b</para>
/// </summary>
        MkldnnNCdhw4c = 71,
        /// <summary>
/// <para>5D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBcde8b</para>
/// </summary>
        MkldnnNCdhw8c = 79,
        /// <summary>
/// <para>4D CNN activations tensor blocked by channels with block size 16,</para>
/// <para>an alias to #mkldnn_aBcd16b</para>
/// </summary>
        MkldnnNChw16c = 40,
        /// <summary>
/// <para>4D CNN activations tensor blocked by channels with block size 4,</para>
/// <para>an alias to #mkldnn_aBcd4b</para>
/// </summary>
        MkldnnNChw4c = 45,
        /// <summary>
/// <para>4D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBcd8b</para>
/// </summary>
        MkldnnNChw8c = 52,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 16,</para>
/// <para>an alias to #mkldnn_aBc16b</para>
/// </summary>
        MkldnnNCw16c = 25,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 4,</para>
/// <para>an alias to #mkldnn_aBc4b</para>
/// </summary>
        MkldnnNCw4c = 28,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnNCw8c = 33,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnNCw16n16c = 24,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnNCdhw16n16c = 63,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnNChw16n16c = 38,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnNChw32n32c = 39,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnIOw16o16i = 127,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnIOw16i16o = 128,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIw16i16o = 26,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIw16o16i = 24,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOiw16o = 23,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIw4i16o4i = 29,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIw4i4o = 30,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOiw4o = 27,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIw8i16o2i = 34,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIw8i8o = 36,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIw8o16i2o = 31,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnIOw8o16i2o = 35,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIw8o8i = 32,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOwi16o = 113,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOwi4o = 114,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOwi8o = 115,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnIOhw16i16o = 130,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnIOhw16o16i = 129,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOhwi16o = 120,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOhwi32o = 121,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOhwi4o = 122,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOhwi8o = 123,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw16i16o = 41,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw16o16i = 38,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOihw16o = 37,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw4i16o4i = 46,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw4i4o = 47,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOihw4o = 44,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw8i16o2i = 53,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw8i8o = 56,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw8o16i2o = 50,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnIOhw8o16i2o = 55,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw8o8i = 51,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOdhwi16o = 124,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOdhwi4o = 125,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOdhwi8o = 126,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIdhw16i16o = 66,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIdhw16o16i = 63,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOidhw16o = 62,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIdhw4i4o = 72,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOidhw4o = 70,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIdhw8i16o2i = 80,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIdhw8i8o = 83,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIdhw8o16i2o = 59,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnIOdhw8o16i2o = 64,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIdhw8o8i = 77,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnIOdhw16i16o = 78,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGoiw16g = 37,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGIOw16o16i = 116,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGIOw16i16o = 117,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIw16i16o = 43,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIw16o16i = 42,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOiw16o = 40,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIw4i16o4i = 48,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIw4i4o = 49,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOiw4o = 45,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIw8i16o2i = 58,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIw8i8o = 61,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIw8o16i2o = 54,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGIOw8o16i2o = 60,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIw8o8i = 57,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOwi16o = 101,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOwi4o = 102,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOwi8o = 103,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGIOhw16i16o = 119,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGIOhw16o16i = 118,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOhwi16o = 104,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOhwi32o = 105,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOhwi4o = 106,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOhwi8o = 107,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGoihw16g = 62,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw16i16o = 68,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw16o16i = 67,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOihw16o = 65,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw2i8o4i = 69,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw4i16o4i = 74,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw4i4o = 75,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw4o4i = 73,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOihw4o = 71,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGoihw8g = 76,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw8i16o2i = 89,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw8i8o = 90,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw8o16i2o = 81,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGIOhw8o16i2o = 82,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw8o8i = 84,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw4o8i8o4i = 85,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnOIhw2o8i8o2i = 86,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw4o8i8o4i = 87,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIhw2o8i8o2i = 88,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGIOdhw16i16o = 109,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOdhwi16o = 108,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOdhwi4o = 110,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOdhwi8o = 111,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIdhw16i16o = 93,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIdhw16o16i = 92,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOidhw16o = 91,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIdhw4i4o = 95,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOidhw4o = 94,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIdhw8i16o2i = 97,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIdhw8i8o = 100,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIdhw8o16i2o = 98,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGIOdhw8o16i2o = 99,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGOIdhw8o8i = 96,
        /// <summary>
/// <para>3D CNN activations tensor blocked by channels with block size 8,</para>
/// <para>an alias to #mkldnn_aBc8b</para>
/// </summary>
        MkldnnGoidhw16g = 112
    }

    /// <summary>Kinds of propagation.</summary>
    public enum MkldnnPropKindT
    {
        /// <summary>Undefined propagation type.</summary>
        MkldnnPropKindUndef = 0,
        /// <summary>
/// <para>Forward data propagation (training mode). In this mode primitives</para>
/// <para>perform computations necessary for subsequent backward propagation.</para>
/// </summary>
        MkldnnForwardTraining = 64,
        /// <summary>
/// <para>Forward data propagation (inference mode). In this mode primitives</para>
/// <para>perform only computations that are necessary for inference and omit</para>
/// <para>computations that are necessary only for backward propagation.</para>
/// </summary>
        MkldnnForwardInference = 96,
        /// <summary>Forward data propagation (alias for</summary>
        MkldnnForwardScoring = 96,
        /// <summary>Forward data propagation (alias for</summary>
        MkldnnForward = 64,
        /// <summary>Backward propagation (with respect to all parameters).</summary>
        MkldnnBackward = 128,
        /// <summary>Backward data propagation.</summary>
        MkldnnBackwardData = 160,
        /// <summary>Backward weights propagation.</summary>
        MkldnnBackwardWeights = 192,
        /// <summary>Backward bias propagation.</summary>
        MkldnnBackwardBias = 193
    }

    /// <summary>
/// <para>Kinds of primitives. Used to implement a way to extend the library with new</para>
/// <para>primitives without changing the ABI.</para>
/// </summary>
    public enum MkldnnPrimitiveKindT
    {
        /// <summary>Undefined primitive</summary>
        MkldnnUndefinedPrimitive = 0,
        /// <summary>A reorder primitive.</summary>
        MkldnnReorder = 1,
        /// <summary>A shuffle primitive.</summary>
        MkldnnShuffle = 2,
        /// <summary>A (out-of-place) concat primitive.</summary>
        MkldnnConcat = 3,
        /// <summary>A sum primitive.</summary>
        MkldnnSum = 4,
        /// <summary>A convolution primitive.</summary>
        MkldnnConvolution = 5,
        /// <summary>A deconvolution primitive.</summary>
        MkldnnDeconvolution = 6,
        /// <summary>An element-wise primitive.</summary>
        MkldnnEltwise = 7,
        /// <summary>A softmax primitive.</summary>
        MkldnnSoftmax = 8,
        /// <summary>A pooling primitive.</summary>
        MkldnnPooling = 9,
        /// <summary>An LRN primitive.</summary>
        MkldnnLrn = 10,
        /// <summary>An batch normalization primitive.</summary>
        MkldnnBatchNormalization = 11,
        /// <summary>An inner product primitive.</summary>
        MkldnnInnerProduct = 12,
        /// <summary>A rnn primitive.</summary>
        MkldnnRnn = 13,
        /// <summary>A matrix multiplication primitive.</summary>
        MkldnnGemm = 14
    }

    /// <summary>Kinds of algorithms.</summary>
    public enum MkldnnAlgKindT
    {
        MkldnnAlgKindUndef = 0,
        /// <summary>Direct convolution</summary>
        MkldnnConvolutionDirect = 1,
        /// <summary>Winograd convolution</summary>
        MkldnnConvolutionWinograd = 2,
        /// <summary>Convolution algorithm(either direct or Winograd) is chosen just in time</summary>
        MkldnnConvolutionAuto = 3,
        /// <summary>Direct deconvolution</summary>
        MkldnnDeconvolutionDirect = 10,
        /// <summary>Winograd deconvolution</summary>
        MkldnnDeconvolutionWinograd = 11,
        /// <summary>Eltwise: ReLU</summary>
        MkldnnEltwiseRelu = 31,
        /// <summary>Eltwise: hyperbolic tangent non-linearity (tanh)</summary>
        MkldnnEltwiseTanh = 47,
        /// <summary>Eltwise: parametric exponential linear unit (elu)</summary>
        MkldnnEltwiseElu = 63,
        /// <summary>Eltwise: square</summary>
        MkldnnEltwiseSquare = 79,
        /// <summary>Eltwise: abs</summary>
        MkldnnEltwiseAbs = 95,
        /// <summary>Eltwise: square root</summary>
        MkldnnEltwiseSqrt = 111,
        /// <summary>Eltwise: linear</summary>
        MkldnnEltwiseLinear = 127,
        /// <summary>Eltwise: bounded_relu</summary>
        MkldnnEltwiseBoundedRelu = 143,
        /// <summary>Eltwise: soft_relu</summary>
        MkldnnEltwiseSoftRelu = 159,
        /// <summary>Eltwise: logistic</summary>
        MkldnnEltwiseLogistic = 175,
        /// <summary>Eltwise: exponent</summary>
        MkldnnEltwiseExp = 191,
        /// <summary>Eltwise: gelu</summary>
/// <remarks>
/// <para>Tanh approximation formula is used to approximate</para>
/// <para>cumulative distribution function of a Gaussian</para>
/// </remarks>
        MkldnnEltwiseGelu = 207,
        /// <summary>Max pooling</summary>
        MkldnnPoolingMax = 511,
        /// <summary>Average pooling include padding</summary>
        MkldnnPoolingAvgIncludePadding = 767,
        /// <summary>Average pooling exclude padding</summary>
        MkldnnPoolingAvgExcludePadding = 1023,
        /// <summary>Average pooling exclude padding</summary>
        MkldnnPoolingAvg = 1023,
        /// <summary>Local response normalization (LRN) across multiple channels</summary>
        MkldnnLrnAcrossChannels = 2815,
        /// <summary>LRN within a single channel</summary>
        MkldnnLrnWithinChannel = 3071,
        /// <summary>RNN cell</summary>
        MkldnnVanillaRnn = 8191,
        /// <summary>LSTM cell</summary>
        MkldnnVanillaLstm = 12287,
        /// <summary>GRU cell</summary>
        MkldnnVanillaGru = 16383,
        /// <summary>GRU cell with linear before reset</summary>
/// <remarks>
/// <para>Modification of original GRU cell. Differs from #mkldnn_vanilla_gru</para>
/// <para>in how the new memory gate is calculated:</para>
/// <para>Primitive expects 4 biases on input:</para>
/// </remarks>
        MkldnnLbrGru = 20479
    }

    /// <summary>Flags for batch normalization primitive.</summary>
    [Flags]
    public enum MkldnnNormalizationFlagsT
    {
        /// <summary>Use global statistics</summary>
/// <remarks>
/// <para>If specified</para>
/// <para>- on forward propagation use mean and variance provided by user (input)</para>
/// <para>- on backward propagation reduces the amount of computations, since</para>
/// <para>mean and variance are considered as constants</para>
/// <para>If not specified:</para>
/// <para>- on forward propagation mean and variance are computed and stored in</para>
/// <para>output</para>
/// <para>- on backward propagation compute full derivative wrt to data</para>
/// </remarks>
        MkldnnUseGlobalStats = 1,
        /// <summary>Use scale and shift parameters</summary>
/// <remarks>
/// <para>If specified:</para>
/// <para>- on forward propagation use scale and shift (aka scale and bias) for</para>
/// <para>the batch normalization results</para>
/// <para>- on backward propagation (for prop_kind == #mkldnn_backward) compute</para>
/// <para>diff wrt to scale and shift (hence one extra output used)</para>
/// <para>If no specified:</para>
/// <para>- on backward propagation prop_kind == #mkldnn_backward_data has the</para>
/// <para>same behavior as prop_kind == #mkldnn_backward</para>
/// </remarks>
        MkldnnUseScaleshift = 2,
        /// <summary>Fuse with ReLU</summary>
/// <remarks>
/// <para>If specified:</para>
/// <para>- on inference this option behaves the same as if the primitive were</para>
/// <para>fused with ReLU via post ops API</para>
/// <para>- on training primitive requires workspace (required to be able to</para>
/// <para>perform backward pass)</para>
/// </remarks>
        MkldnnFuseNormRelu = 4
    }

    /// <summary>Winograd-specific formats</summary>
    public enum MkldnnWinoMemoryFormatT
    {
        /// <summary>Undefined memory format, used for empty memory descriptors.</summary>
        MkldnnWinoUndef = 0,
        /// <summary>Internal weights format for 2x3 Winograd</summary>
        MkldnnWinoWeiAaOIoi = 1,
        /// <summary>Internal weights format for 2x3 Winograd</summary>
        MkldnnWinoWeiAaOio = 2,
        /// <summary>Internal weights format for 2x3 Winograd</summary>
        MkldnnWinoWeiAaOBiOo = 3,
        /// <summary>Internal weights format for 4x3 Winograd</summary>
        MkldnnWinoWeiOBaaIBOIio = 4
    }

    public enum MkldnnRnnPackedMemoryFormatT
    {
        MkldnnPackedFormatUndef = 0,
        MkldnnLdigoP = 1,
        MkldnnLdgoiP = 2
    }

    /// <summary>Flags for memory special features</summary>
    public enum MkldnnMemoryExtraFlagsT
    {
        MkldnnMemoryExtraFlagNone = 0,
        /// <summary>Indicates the weights have an additional buffer, that depends on the</summary>
/// <remarks>
/// <para>For instance, in 4D case with the compensation mask equals (1&lt;&gt;&lt;&gt;0)</para>
/// <para>the additional buffer would consist of OC values:</para>
/// <para>O[oc : 0,OC] =</para>
/// <para>-128 * SUM(ic : 0,IC; kh : 0,KH; kw : 0,KW){ weights(oc, ic, kh, kw) }</para>
/// </remarks>
        MkldnnMemoryExtraFlagCompensationConvS8s8 = 1,
        /// <summary>Indicates the weights have an additional buffer, that depends on the</summary>
/// <remarks>
/// <para>For instance, in 4D case with the compensation mask equals (1&lt;&gt;&lt;&gt;0)</para>
/// <para>the additional buffer would consist of OC values:</para>
/// <para>O[oc : 0,OC] =</para>
/// <para>-128 * SUM(ic : 0,IC; kh : 0,KH; kw : 0,KW){ weights(oc, ic, kh, kw) }</para>
/// </remarks>
        MkldnnMemoryExtraFlagScaleAdjust = 2
    }

    /// <summary>Flags for RNN cell.</summary>
    public enum MkldnnRnnFlagsT
    {
        MkldnnRnnFlagsUndef = 0
    }

    /// <summary>A direction of RNN primitive execution.</summary>
    public enum MkldnnRnnDirectionT
    {
        /// <summary>Unidirectional execution of RNN primitive from left to right.</summary>
        MkldnnUnidirectionalLeft2right = 0,
        /// <summary>Unidirectional execution of RNN primitive from right to left.</summary>
        MkldnnUnidirectionalRight2left = 1,
        /// <summary>
/// <para>Bidirectional execution of RNN primitive with concatenation of the</para>
/// <para>results.</para>
/// </summary>
        MkldnnBidirectionalConcat = 2,
        /// <summary>
/// <para>Bidirectional execution of RNN primitive with summation of the</para>
/// <para>results.</para>
/// </summary>
        MkldnnBidirectionalSum = 3,
        /// <summary>
/// <para>Bidirectional execution of RNN primitive with summation of the</para>
/// <para>results.</para>
/// </summary>
        MkldnnUnidirectional = 0
    }

    /// <summary>Kinds of engines.</summary>
    public enum MkldnnEngineKindT
    {
        /// <summary>An unspecified engine.</summary>
        MkldnnAnyEngine = 0,
        /// <summary>CPU engine.</summary>
        MkldnnCpu = 1,
        /// <summary>GPU engine.</summary>
        MkldnnGpu = 2
    }

    /// <summary>Scratchpad mode</summary>
    public enum MkldnnScratchpadModeT
    {
        /// <summary>The library manages scratchpad (default)</summary>
        MkldnnScratchpadModeLibrary = 0,
        /// <summary>A user shall query and provide the scratchpad memory to primitives</summary>
        MkldnnScratchpadModeUser = 1
    }

    /// <summary>Primitive descriptor query specification</summary>
/// <remarks>
/// <para>For generic function mkldnn_primitive_desc_query(), the type of result must</para>
/// <para>agree with the queried argument. The correspondence table:</para>
/// <para>Query                           | type of result</para>
/// <para>--------------------------------------------------------------</para>
/// <para>#mkldnn_query_engine            | mkldnn_engine_t *</para>
/// <para>#mkldnn_query_scratchpad_engine | mkldnn_engine_t *</para>
/// <para>#mkldnn_query_primitive_kind    | mkldnn_primitive_kind_t *</para>
/// <para>*_s32                           | int *</para>
/// <para>*_s64                           | mkldnn_dim_t * (same as int64_t *)</para>
/// <para>*_f64                           | double *</para>
/// <para>*_str                           | const char **</para>
/// <para>#mkldnn_query_op_d              | const_mkldnn_op_desc_t *</para>
/// <para>*_md                            | const mkldnn_memory_desc_t **</para>
/// <para>*_${op}_d                       | const mkldnn_${op}_desc_t **</para>
/// <para>*_pd                            | const_mkldnn_primitive_desc_t *</para>
/// <para>Rule of thumb: all opaque types and structures are returned by</para>
/// <para>reference. All numbers are returned by value.</para>
/// <para>All returned references point to constant objects and are valid only</para>
/// <para>during the lifetime of the queried primitive descriptor. Returned objects</para>
/// <para>must not be destroyed by the user. If you need to keep the object longer</para>
/// <para>than the lifetime of the queried primitive descriptor, use</para>
/// <para>mkldnn_primitive_desc_clone() to make a copy.</para>
/// </remarks>
    public enum MkldnnQueryT
    {
        /// <summary>no query</summary>
        MkldnnQueryUndef = 0,
        /// <summary>execution engine</summary>
        MkldnnQueryEngine = 1,
        /// <summary>primitive kind</summary>
        MkldnnQueryPrimitiveKind = 2,
        /// <summary>number of inputs expected</summary>
        MkldnnQueryNumOfInputsS32 = 3,
        /// <summary>number of outputs expected</summary>
        MkldnnQueryNumOfOutputsS32 = 4,
        /// <summary>runtime estimation (seconds)</summary>
        MkldnnQueryTimeEstimateF64 = 5,
        /// <summary>memory consumption -- extra</summary>
        MkldnnQueryMemoryConsumptionS64 = 6,
        /// <summary>scratchpad engine -- engine to be used</summary>
        MkldnnQueryScratchpadEngine = 7,
        /// <summary>implementation name</summary>
        MkldnnQueryImplInfoStr = 8,
        /// <summary>stub</summary>
        MkldnnQuerySomeD = 64,
        /// <summary>op descriptor</summary>
        MkldnnQueryOpD = 65,
        /// <summary>convolution descriptor</summary>
        MkldnnQueryConvolutionD = 66,
        /// <summary>deconvolution descriptor</summary>
        MkldnnQueryDeconvolutionD = 67,
        /// <summary>shuffle descriptor</summary>
        MkldnnQueryShuffleD = 68,
        /// <summary>eltwise descriptor</summary>
        MkldnnQueryEltwiseD = 69,
        /// <summary>softmax descriptor</summary>
        MkldnnQuerySoftmaxD = 70,
        /// <summary>pooling descriptor</summary>
        MkldnnQueryPoolingD = 71,
        /// <summary>lrn descriptor</summary>
        MkldnnQueryLrnD = 72,
        /// <summary>batch normalization descriptor</summary>
        MkldnnQueryBatchNormalizationD = 73,
        /// <summary>inner product descriptor</summary>
        MkldnnQueryInnerProductD = 74,
        /// <summary>rnn descriptor</summary>
        MkldnnQueryRnnD = 75,
        /// <summary>GEMM descriptor</summary>
        MkldnnQueryGemmD = 76,
        /// <summary>stub</summary>
        MkldnnQuerySomeMd = 128,
        /// <summary>source memory desc</summary>
        MkldnnQuerySrcMd = 129,
        /// <summary>source gradient memory desc</summary>
        MkldnnQueryDiffSrcMd = 130,
        /// <summary>weights memory descriptor desc</summary>
        MkldnnQueryWeightsMd = 131,
        /// <summary>weights grad. memory desc</summary>
        MkldnnQueryDiffWeightsMd = 132,
        /// <summary>destination memory desc</summary>
        MkldnnQueryDstMd = 133,
        /// <summary>destination grad. memory desc</summary>
        MkldnnQueryDiffDstMd = 134,
        /// <summary>workspace memory desc</summary>
        MkldnnQueryWorkspaceMd = 135,
        /// <summary>scratchpad memory desc</summary>
        MkldnnQueryScratchpadMd = 136
    }

    /// <summary>Stream flags.</summary>
    [Flags]
    public enum MkldnnStreamFlagsT
    {
        /// <summary>
/// <para>Default order execution. Either in-order or out-of-order depending on</para>
/// <para>the runtime.</para>
/// </summary>
        MkldnnStreamDefaultOrder = 1,
        /// <summary>In-order execution.</summary>
        MkldnnStreamInOrder = 2,
        /// <summary>Out-of-order execution.</summary>
        MkldnnStreamOutOfOrder = 4,
        /// <summary>Default stream configuration.</summary>
        MkldnnStreamDefaultFlags = 1
    }

    /// <summary>A type to describe tensor dimension.</summary>
    /// <summary>A type to describe tensor dimensions.</summary>
    /// <summary>A memory handle.</summary>
    /// <summary>A constant memory handle.</summary>
    /// <summary>A pointer to any of the operation descriptors.</summary>
    /// <summary>A pointer to any of the operation descriptors (constant variant).</summary>
    /// <summary>A descriptor of a deconvolution operation.</summary>
    /// <summary>An engine handle.</summary>
    /// <summary>A primitive descriptor iterator handle.</summary>
    /// <summary>A constant primitive descriptor iterator handle.</summary>
    /// <summary>A primitive descriptor handle.</summary>
    /// <summary>A constant primitive descriptor handle.</summary>
    /// <summary>
/// <para>A primitive descriptor attributes handle that controls primitive</para>
/// <para>behavior.</para>
/// </summary>
    /// <summary>A constant primitive descriptor attributes handle.</summary>
    /// <summary>A post operation chain handle.</summary>
    /// <summary>A constant post operation chain handle.</summary>
    /// <summary>A primitive handle.</summary>
    /// <summary>A constant primitive handle.</summary>
    /// <summary>An execution stream handle.</summary>
    /// <summary>A constant execution stream handle.</summary>
    /// <summary>An opaque structure to describe a memory.</summary>
    public unsafe partial class MkldnnMemory
    {
        [StructLayout(LayoutKind.Explicit, Size = 0)]
        public partial struct __Internal
        {
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnMemory> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnMemory>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnMemory __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnMemory(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnMemory __CreateInstance(global::Intel.MklDnn.MkldnnMemory.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnMemory(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnMemory.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnMemory.__Internal));
            *(global::Intel.MklDnn.MkldnnMemory.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnMemory(global::Intel.MklDnn.MkldnnMemory.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnMemory(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }
    }

    /// <summary>An opaque structure to describe an engine.</summary>
    public unsafe partial class MkldnnEngine
    {
        [StructLayout(LayoutKind.Explicit, Size = 0)]
        public partial struct __Internal
        {
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnEngine> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnEngine>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnEngine __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnEngine(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnEngine __CreateInstance(global::Intel.MklDnn.MkldnnEngine.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnEngine(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnEngine.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnEngine.__Internal));
            *(global::Intel.MklDnn.MkldnnEngine.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnEngine(global::Intel.MklDnn.MkldnnEngine.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnEngine(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }
    }

    /// <summary>An opaque structure to describe a primitive descriptor iterator.</summary>
    public unsafe partial class MkldnnPrimitiveDescIterator
    {
        [StructLayout(LayoutKind.Explicit, Size = 0)]
        public partial struct __Internal
        {
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPrimitiveDescIterator> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPrimitiveDescIterator>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnPrimitiveDescIterator __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPrimitiveDescIterator(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnPrimitiveDescIterator __CreateInstance(global::Intel.MklDnn.MkldnnPrimitiveDescIterator.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPrimitiveDescIterator(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnPrimitiveDescIterator.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnPrimitiveDescIterator.__Internal));
            *(global::Intel.MklDnn.MkldnnPrimitiveDescIterator.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnPrimitiveDescIterator(global::Intel.MklDnn.MkldnnPrimitiveDescIterator.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnPrimitiveDescIterator(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }
    }

    /// <summary>An opaque structure to describe a primitive descriptor.</summary>
    public unsafe partial class MkldnnPrimitiveDesc
    {
        [StructLayout(LayoutKind.Explicit, Size = 0)]
        public partial struct __Internal
        {
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPrimitiveDesc> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPrimitiveDesc>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnPrimitiveDesc __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPrimitiveDesc(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnPrimitiveDesc __CreateInstance(global::Intel.MklDnn.MkldnnPrimitiveDesc.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPrimitiveDesc(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnPrimitiveDesc.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnPrimitiveDesc.__Internal));
            *(global::Intel.MklDnn.MkldnnPrimitiveDesc.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnPrimitiveDesc(global::Intel.MklDnn.MkldnnPrimitiveDesc.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnPrimitiveDesc(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }
    }

    /// <summary>An opaque structure for primitive descriptor attributes.</summary>
/// <remarks>
/// <para>Attributes may contain:</para>
/// <para>- output scales (to scale the result prior to storing it to the memory)</para>
/// </remarks>
    public unsafe partial class MkldnnPrimitiveAttr
    {
        [StructLayout(LayoutKind.Explicit, Size = 0)]
        public partial struct __Internal
        {
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPrimitiveAttr> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPrimitiveAttr>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnPrimitiveAttr __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPrimitiveAttr(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnPrimitiveAttr __CreateInstance(global::Intel.MklDnn.MkldnnPrimitiveAttr.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPrimitiveAttr(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnPrimitiveAttr.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnPrimitiveAttr.__Internal));
            *(global::Intel.MklDnn.MkldnnPrimitiveAttr.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnPrimitiveAttr(global::Intel.MklDnn.MkldnnPrimitiveAttr.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnPrimitiveAttr(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }
    }

    /// <summary>An opaque structure for a chain of post operations.</summary>
/// <remarks>
/// <para>mkldnn_post_ops can be used to perform some (trivial) operations like</para>
/// <para>accumulation or eltwise after certain primitives like convolution.</para>
/// <para>Post operations might be combined together, making a chain of post</para>
/// <para>operations. For instance one can configure convolution followed by</para>
/// <para>accumulation followed by eltwise. This might be especially beneficial</para>
/// <para>for residual learning blocks.</para>
/// <para>Of course not all combinations are supported, so the user should handle</para>
/// <para>errors accordingly.</para>
/// <para>Supported post operations:</para>
/// <para>- accumulation (base primitive: convolution)</para>
/// <para>- eltwise (base primitive: convolution)</para>
/// </remarks>
    public unsafe partial class MkldnnPostOps
    {
        [StructLayout(LayoutKind.Explicit, Size = 0)]
        public partial struct __Internal
        {
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPostOps> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPostOps>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnPostOps __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPostOps(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnPostOps __CreateInstance(global::Intel.MklDnn.MkldnnPostOps.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPostOps(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnPostOps.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnPostOps.__Internal));
            *(global::Intel.MklDnn.MkldnnPostOps.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnPostOps(global::Intel.MklDnn.MkldnnPostOps.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnPostOps(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }
    }

    /// <summary>An opaque structure to describe a primitive.</summary>
    public unsafe partial class MkldnnPrimitive
    {
        [StructLayout(LayoutKind.Explicit, Size = 0)]
        public partial struct __Internal
        {
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPrimitive> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPrimitive>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnPrimitive __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPrimitive(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnPrimitive __CreateInstance(global::Intel.MklDnn.MkldnnPrimitive.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPrimitive(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnPrimitive.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnPrimitive.__Internal));
            *(global::Intel.MklDnn.MkldnnPrimitive.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnPrimitive(global::Intel.MklDnn.MkldnnPrimitive.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnPrimitive(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }
    }

    /// <summary>An opaque structure to describe an execution stream.</summary>
    public unsafe partial class MkldnnStream
    {
        [StructLayout(LayoutKind.Explicit, Size = 0)]
        public partial struct __Internal
        {
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnStream> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnStream>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnStream __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnStream(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnStream __CreateInstance(global::Intel.MklDnn.MkldnnStream.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnStream(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnStream.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnStream.__Internal));
            *(global::Intel.MklDnn.MkldnnStream.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnStream(global::Intel.MklDnn.MkldnnStream.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnStream(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }
    }

    /// <summary>Version type</summary>
    public unsafe partial class MkldnnVersionT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 24)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal int major;

            [FieldOffset(4)]
            internal int minor;

            [FieldOffset(8)]
            internal int patch;

            [FieldOffset(16)]
            internal global::System.IntPtr hash;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_version_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnVersionT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnVersionT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnVersionT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnVersionT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnVersionT __CreateInstance(global::Intel.MklDnn.MkldnnVersionT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnVersionT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnVersionT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnVersionT.__Internal));
            *(global::Intel.MklDnn.MkldnnVersionT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnVersionT(global::Intel.MklDnn.MkldnnVersionT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnVersionT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnVersionT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnVersionT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnVersionT(global::Intel.MklDnn.MkldnnVersionT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnVersionT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnVersionT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnVersionT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnVersionT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public int Major
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnVersionT.__Internal*) __Instance)->major;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnVersionT.__Internal*)__Instance)->major = value;
            }
        }

        public int Minor
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnVersionT.__Internal*) __Instance)->minor;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnVersionT.__Internal*)__Instance)->minor = value;
            }
        }

        public int Patch
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnVersionT.__Internal*) __Instance)->patch;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnVersionT.__Internal*)__Instance)->patch = value;
            }
        }

        public string Hash
        {
            get
            {
                return Marshal.PtrToStringAnsi(((global::Intel.MklDnn.MkldnnVersionT.__Internal*) __Instance)->hash);
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnVersionT.__Internal*)__Instance)->hash = (global::System.IntPtr) Marshal.StringToHGlobalAnsi(value);
            }
        }
    }

    /// <summary>Generic description of blocked data layout for most memory formats.</summary>
    public unsafe partial class MkldnnBlockingDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 296)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal fixed long strides[12];

            [FieldOffset(96)]
            internal int inner_nblks;

            [FieldOffset(104)]
            internal fixed long inner_blks[12];

            [FieldOffset(200)]
            internal fixed long inner_idxs[12];

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_blocking_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnBlockingDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnBlockingDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnBlockingDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnBlockingDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnBlockingDescT __CreateInstance(global::Intel.MklDnn.MkldnnBlockingDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnBlockingDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnBlockingDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnBlockingDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnBlockingDescT(global::Intel.MklDnn.MkldnnBlockingDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnBlockingDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnBlockingDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnBlockingDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnBlockingDescT(global::Intel.MklDnn.MkldnnBlockingDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnBlockingDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnBlockingDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public long[] Strides
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) __Instance)->strides != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) __Instance)->strides[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*)__Instance)->strides[i] = value[i];
                }
            }
        }

        public int InnerNblks
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) __Instance)->inner_nblks;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*)__Instance)->inner_nblks = value;
            }
        }

        public long[] InnerBlks
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) __Instance)->inner_blks != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) __Instance)->inner_blks[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*)__Instance)->inner_blks[i] = value[i];
                }
            }
        }

        public long[] InnerIdxs
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) __Instance)->inner_idxs != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) __Instance)->inner_idxs[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*)__Instance)->inner_idxs[i] = value[i];
                }
            }
        }
    }

    /// <summary>Description of tensor of weights for winograd 2x3 convolution.</summary>
    public unsafe partial class MkldnnWinoDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 48)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnWinoMemoryFormatT wino_format;

            [FieldOffset(4)]
            internal int r;

            [FieldOffset(8)]
            internal int alpha;

            [FieldOffset(12)]
            internal int ic;

            [FieldOffset(16)]
            internal int oc;

            [FieldOffset(20)]
            internal int ic_block;

            [FieldOffset(24)]
            internal int oc_block;

            [FieldOffset(28)]
            internal int ic2_block;

            [FieldOffset(32)]
            internal int oc2_block;

            [FieldOffset(36)]
            internal float adj_scale;

            [FieldOffset(40)]
            internal ulong size;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_wino_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnWinoDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnWinoDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnWinoDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnWinoDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnWinoDescT __CreateInstance(global::Intel.MklDnn.MkldnnWinoDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnWinoDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnWinoDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnWinoDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnWinoDescT(global::Intel.MklDnn.MkldnnWinoDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnWinoDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnWinoDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnWinoDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnWinoDescT(global::Intel.MklDnn.MkldnnWinoDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnWinoDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnWinoDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnWinoMemoryFormatT WinoFormat
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->wino_format;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->wino_format = value;
            }
        }

        public int R
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->r;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->r = value;
            }
        }

        public int Alpha
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->alpha;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->alpha = value;
            }
        }

        public int Ic
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->ic;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->ic = value;
            }
        }

        public int Oc
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->oc;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->oc = value;
            }
        }

        public int IcBlock
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->ic_block;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->ic_block = value;
            }
        }

        public int OcBlock
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->oc_block;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->oc_block = value;
            }
        }

        public int Ic2Block
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->ic2_block;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->ic2_block = value;
            }
        }

        public int Oc2Block
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->oc2_block;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->oc2_block = value;
            }
        }

        public float AdjScale
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->adj_scale;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->adj_scale = value;
            }
        }

        public ulong Size
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) __Instance)->size;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnWinoDescT.__Internal*)__Instance)->size = value;
            }
        }
    }

    /// <summary>Description of tensor of packed weights for rnn.</summary>
    public unsafe partial class MkldnnRnnPackedDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 296)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnRnnPackedMemoryFormatT format;

            [FieldOffset(4)]
            internal int n_parts;

            [FieldOffset(8)]
            internal int n;

            [FieldOffset(12)]
            internal int ldb;

            [FieldOffset(16)]
            internal fixed int parts[4];

            [FieldOffset(32)]
            internal fixed ulong part_pack_size[4];

            [FieldOffset(64)]
            internal fixed uint pack_part[4];

            [FieldOffset(80)]
            internal ulong offset_compensation;

            [FieldOffset(88)]
            internal ulong size;

            [FieldOffset(96)]
            internal fixed sbyte reserved[200];

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_rnn_packed_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnRnnPackedDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnRnnPackedDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnRnnPackedDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnRnnPackedDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnRnnPackedDescT __CreateInstance(global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnRnnPackedDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnRnnPackedDescT(global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnRnnPackedDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnRnnPackedDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnRnnPackedDescT(global::Intel.MklDnn.MkldnnRnnPackedDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnRnnPackedDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnRnnPackedMemoryFormatT Format
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->format;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->format = value;
            }
        }

        public int NParts
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->n_parts;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->n_parts = value;
            }
        }

        public int N
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->n;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->n = value;
            }
        }

        public int Ldb
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->ldb;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->ldb = value;
            }
        }

        public int[] Parts
        {
            get
            {
                int[] __value = null;
                if (((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->parts != null)
                {
                    __value = new int[4];
                    for (int i = 0; i < 4; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->parts[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 4; i++)
                        ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->parts[i] = value[i];
                }
            }
        }

        public ulong[] PartPackSize
        {
            get
            {
                ulong[] __value = null;
                if (((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->part_pack_size != null)
                {
                    __value = new ulong[4];
                    for (int i = 0; i < 4; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->part_pack_size[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 4; i++)
                        ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->part_pack_size[i] = value[i];
                }
            }
        }

        public uint[] PackPart
        {
            get
            {
                uint[] __value = null;
                if (((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->pack_part != null)
                {
                    __value = new uint[4];
                    for (int i = 0; i < 4; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->pack_part[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 4; i++)
                        ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->pack_part[i] = value[i];
                }
            }
        }

        public ulong OffsetCompensation
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->offset_compensation;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->offset_compensation = value;
            }
        }

        public ulong Size
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->size;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->size = value;
            }
        }

        public sbyte[] Reserved
        {
            get
            {
                sbyte[] __value = null;
                if (((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->reserved != null)
                {
                    __value = new sbyte[200];
                    for (int i = 0; i < 200; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) __Instance)->reserved[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 200; i++)
                        ((global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*)__Instance)->reserved[i] = value[i];
                }
            }
        }
    }

    /// <summary>Description of extra information stored in memory</summary>
    public unsafe partial class MkldnnMemoryExtraDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 80)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal ulong flags;

            [FieldOffset(8)]
            internal int compensation_mask;

            [FieldOffset(12)]
            internal float scale_adjust;

            [FieldOffset(16)]
            internal fixed sbyte reserved[64];

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_memory_extra_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnMemoryExtraDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnMemoryExtraDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnMemoryExtraDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnMemoryExtraDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnMemoryExtraDescT __CreateInstance(global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnMemoryExtraDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnMemoryExtraDescT(global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnMemoryExtraDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnMemoryExtraDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnMemoryExtraDescT(global::Intel.MklDnn.MkldnnMemoryExtraDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnMemoryExtraDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public ulong Flags
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) __Instance)->flags;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*)__Instance)->flags = value;
            }
        }

        public int CompensationMask
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) __Instance)->compensation_mask;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*)__Instance)->compensation_mask = value;
            }
        }

        public float ScaleAdjust
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) __Instance)->scale_adjust;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*)__Instance)->scale_adjust = value;
            }
        }

        public sbyte[] Reserved
        {
            get
            {
                sbyte[] __value = null;
                if (((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) __Instance)->reserved != null)
                {
                    __value = new sbyte[64];
                    for (int i = 0; i < 64; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) __Instance)->reserved[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 64; i++)
                        ((global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*)__Instance)->reserved[i] = value[i];
                }
            }
        }
    }

    /// <summary>
/// <para>Memory descriptor. The description is based on a number of dimensions,</para>
/// <para>dimensions themselves, plus information about elements type and memory</para>
/// <para>format. Additionally, contains format-specific descriptions of the data</para>
/// <para>layout.</para>
/// </summary>
    public unsafe partial class MkldnnMemoryDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 696)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal int ndims;

            [FieldOffset(8)]
            internal fixed long dims[12];

            [FieldOffset(104)]
            internal global::Intel.MklDnn.MkldnnDataTypeT data_type;

            [FieldOffset(112)]
            internal fixed long padded_dims[12];

            [FieldOffset(208)]
            internal fixed long padded_offsets[12];

            [FieldOffset(304)]
            internal long offset0;

            [FieldOffset(312)]
            internal global::Intel.MklDnn.MkldnnFormatKindT format_kind;

            [FieldOffset(320)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc.__Internal format_desc;

            [FieldOffset(616)]
            internal global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal extra;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_memory_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public unsafe partial struct FormatDesc
        {
            [StructLayout(LayoutKind.Explicit, Size = 296)]
            public partial struct __Internal
            {
                [FieldOffset(0)]
                internal global::Intel.MklDnn.MkldnnBlockingDescT.__Internal blocking;

                [FieldOffset(0)]
                internal global::Intel.MklDnn.MkldnnWinoDescT.__Internal wino_desc;

                [FieldOffset(0)]
                internal global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal rnn_packed_desc;

                [SuppressUnmanagedCodeSecurity]
                [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                    EntryPoint="??0<unnamed-type-format_desc>@mkldnn_memory_desc_t@@QEAA@AEBT01@@Z")]
                internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
            }

            private FormatDesc.__Internal __instance;
            internal FormatDesc.__Internal __Instance { get { return __instance; } }

            internal static global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
            {
                return new global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc(native.ToPointer(), skipVTables);
            }

            internal static global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc __CreateInstance(global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc.__Internal native, bool skipVTables = false)
            {
                return new global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc(native, skipVTables);
            }

            private FormatDesc(global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc.__Internal native, bool skipVTables = false)
                : this()
            {
                __instance = native;
            }

            private FormatDesc(void* native, bool skipVTables = false) : this()
            {
                __instance = *(global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc.__Internal*) native;
            }

            public FormatDesc(global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc _0)
                : this()
            {
                var ____arg0 = _0.__Instance;
                var __arg0 = new global::System.IntPtr(&____arg0);
                fixed (__Internal* __instancePtr = &__instance)
                {
                    __Internal.cctor(new global::System.IntPtr(__instancePtr), __arg0);
                }
            }

            public global::Intel.MklDnn.MkldnnBlockingDescT Blocking
            {
                get
                {
                    return global::Intel.MklDnn.MkldnnBlockingDescT.__CreateInstance(__instance.blocking);
                }

                set
                {
                    if (ReferenceEquals(value, null))
                        throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                    __instance.blocking = *(global::Intel.MklDnn.MkldnnBlockingDescT.__Internal*) value.__Instance;
                }
            }

            public global::Intel.MklDnn.MkldnnWinoDescT WinoDesc
            {
                get
                {
                    return global::Intel.MklDnn.MkldnnWinoDescT.__CreateInstance(__instance.wino_desc);
                }

                set
                {
                    if (ReferenceEquals(value, null))
                        throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                    __instance.wino_desc = *(global::Intel.MklDnn.MkldnnWinoDescT.__Internal*) value.__Instance;
                }
            }

            public global::Intel.MklDnn.MkldnnRnnPackedDescT RnnPackedDesc
            {
                get
                {
                    return global::Intel.MklDnn.MkldnnRnnPackedDescT.__CreateInstance(__instance.rnn_packed_desc);
                }

                set
                {
                    if (ReferenceEquals(value, null))
                        throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                    __instance.rnn_packed_desc = *(global::Intel.MklDnn.MkldnnRnnPackedDescT.__Internal*) value.__Instance;
                }
            }
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnMemoryDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnMemoryDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnMemoryDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnMemoryDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnMemoryDescT __CreateInstance(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnMemoryDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnMemoryDescT(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnMemoryDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnMemoryDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnMemoryDescT(global::Intel.MklDnn.MkldnnMemoryDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnMemoryDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public int Ndims
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->ndims;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->ndims = value;
            }
        }

        public long[] Dims
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->dims != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->dims[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->dims[i] = value[i];
                }
            }
        }

        public global::Intel.MklDnn.MkldnnDataTypeT DataType
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->data_type;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->data_type = value;
            }
        }

        public long[] PaddedDims
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->padded_dims != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->padded_dims[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->padded_dims[i] = value[i];
                }
            }
        }

        public long[] PaddedOffsets
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->padded_offsets != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->padded_offsets[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->padded_offsets[i] = value[i];
                }
            }
        }

        public long Offset0
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->offset0;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->offset0 = value;
            }
        }

        public global::Intel.MklDnn.MkldnnFormatKindT FormatKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->format_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->format_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc format_desc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.FormatDesc.__CreateInstance(((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->format_desc);
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->format_desc = value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryExtraDescT Extra
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryExtraDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) __Instance)->extra));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*)__Instance)->extra = *(global::Intel.MklDnn.MkldnnMemoryExtraDescT.__Internal*) value.__Instance;
            }
        }
    }

    /// <summary>A descriptor of a convolution operation.</summary>
    public unsafe partial class MkldnnConvolutionDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 5976)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnAlgKindT alg_kind;

            [FieldOffset(16)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal src_desc;

            [FieldOffset(712)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_src_desc;

            [FieldOffset(1408)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal weights_desc;

            [FieldOffset(2104)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_weights_desc;

            [FieldOffset(2800)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal bias_desc;

            [FieldOffset(3496)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_bias_desc;

            [FieldOffset(4192)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal dst_desc;

            [FieldOffset(4888)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_dst_desc;

            [FieldOffset(5584)]
            internal fixed long strides[12];

            [FieldOffset(5680)]
            internal fixed long dilates[12];

            [FieldOffset(5776)]
            internal fixed long padding[24];

            [FieldOffset(5968)]
            internal global::Intel.MklDnn.MkldnnDataTypeT accum_data_type;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_convolution_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnConvolutionDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnConvolutionDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnConvolutionDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnConvolutionDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnConvolutionDescT __CreateInstance(global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnConvolutionDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnConvolutionDescT(global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnConvolutionDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnConvolutionDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnConvolutionDescT(global::Intel.MklDnn.MkldnnConvolutionDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnConvolutionDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnAlgKindT AlgKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->alg_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->alg_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT SrcDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->src_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->src_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffSrcDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->diff_src_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->diff_src_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT WeightsDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->weights_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->weights_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffWeightsDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->diff_weights_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->diff_weights_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT BiasDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->bias_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->bias_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffBiasDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->diff_bias_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->diff_bias_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DstDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->dst_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->dst_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDstDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->diff_dst_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->diff_dst_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public long[] Strides
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->strides != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->strides[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->strides[i] = value[i];
                }
            }
        }

        public long[] Dilates
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->dilates != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->dilates[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->dilates[i] = value[i];
                }
            }
        }

        public global::Intel.MklDnn.MkldnnDataTypeT AccumDataType
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*) __Instance)->accum_data_type;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnConvolutionDescT.__Internal*)__Instance)->accum_data_type = value;
            }
        }
    }

    /// <summary>A descriptor of a shuffle operation.</summary>
    public unsafe partial class MkldnnShuffleDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 720)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal data_desc;

            [FieldOffset(704)]
            internal int axis;

            [FieldOffset(712)]
            internal long group_size;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_shuffle_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnShuffleDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnShuffleDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnShuffleDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnShuffleDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnShuffleDescT __CreateInstance(global::Intel.MklDnn.MkldnnShuffleDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnShuffleDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnShuffleDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnShuffleDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnShuffleDescT(global::Intel.MklDnn.MkldnnShuffleDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnShuffleDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnShuffleDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnShuffleDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnShuffleDescT(global::Intel.MklDnn.MkldnnShuffleDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnShuffleDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnShuffleDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DataDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*) __Instance)->data_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*)__Instance)->data_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public int Axis
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*) __Instance)->axis;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*)__Instance)->axis = value;
            }
        }

        public long GroupSize
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*) __Instance)->group_size;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnShuffleDescT.__Internal*)__Instance)->group_size = value;
            }
        }
    }

    /// <summary>A descriptor of a element-wise operation.</summary>
    public unsafe partial class MkldnnEltwiseDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 1416)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnAlgKindT alg_kind;

            [FieldOffset(16)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal data_desc;

            [FieldOffset(712)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_data_desc;

            [FieldOffset(1408)]
            internal float alpha;

            [FieldOffset(1412)]
            internal float beta;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_eltwise_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnEltwiseDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnEltwiseDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnEltwiseDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnEltwiseDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnEltwiseDescT __CreateInstance(global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnEltwiseDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnEltwiseDescT(global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnEltwiseDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnEltwiseDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnEltwiseDescT(global::Intel.MklDnn.MkldnnEltwiseDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnEltwiseDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnAlgKindT AlgKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) __Instance)->alg_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*)__Instance)->alg_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DataDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) __Instance)->data_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*)__Instance)->data_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDataDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) __Instance)->diff_data_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*)__Instance)->diff_data_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public float Alpha
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) __Instance)->alpha;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*)__Instance)->alpha = value;
            }
        }

        public float Beta
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*) __Instance)->beta;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnEltwiseDescT.__Internal*)__Instance)->beta = value;
            }
        }
    }

    /// <summary>A descriptor of a Softmax operation.</summary>
    public unsafe partial class MkldnnSoftmaxDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 1408)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal data_desc;

            [FieldOffset(704)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_desc;

            [FieldOffset(1400)]
            internal int softmax_axis;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_softmax_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnSoftmaxDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnSoftmaxDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnSoftmaxDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnSoftmaxDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnSoftmaxDescT __CreateInstance(global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnSoftmaxDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnSoftmaxDescT(global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnSoftmaxDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnSoftmaxDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnSoftmaxDescT(global::Intel.MklDnn.MkldnnSoftmaxDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnSoftmaxDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DataDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*) __Instance)->data_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*)__Instance)->data_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*) __Instance)->diff_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*)__Instance)->diff_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public int SoftmaxAxis
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*) __Instance)->softmax_axis;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnSoftmaxDescT.__Internal*)__Instance)->softmax_axis = value;
            }
        }
    }

    /// <summary>A descriptor of a pooling operation.</summary>
    public unsafe partial class MkldnnPoolingDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 3192)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnAlgKindT alg_kind;

            [FieldOffset(16)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal src_desc;

            [FieldOffset(712)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_src_desc;

            [FieldOffset(1408)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal dst_desc;

            [FieldOffset(2104)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_dst_desc;

            [FieldOffset(2800)]
            internal fixed long strides[12];

            [FieldOffset(2896)]
            internal fixed long kernel[12];

            [FieldOffset(2992)]
            internal fixed long padding[24];

            [FieldOffset(3184)]
            internal global::Intel.MklDnn.MkldnnDataTypeT accum_data_type;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_pooling_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPoolingDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnPoolingDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnPoolingDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPoolingDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnPoolingDescT __CreateInstance(global::Intel.MklDnn.MkldnnPoolingDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnPoolingDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnPoolingDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnPoolingDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnPoolingDescT(global::Intel.MklDnn.MkldnnPoolingDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnPoolingDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnPoolingDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnPoolingDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnPoolingDescT(global::Intel.MklDnn.MkldnnPoolingDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnPoolingDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnPoolingDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnAlgKindT AlgKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->alg_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->alg_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT SrcDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->src_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->src_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffSrcDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->diff_src_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->diff_src_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DstDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->dst_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->dst_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDstDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->diff_dst_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->diff_dst_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public long[] Strides
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->strides != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->strides[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->strides[i] = value[i];
                }
            }
        }

        public long[] Kernel
        {
            get
            {
                long[] __value = null;
                if (((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->kernel != null)
                {
                    __value = new long[12];
                    for (int i = 0; i < 12; i++)
                        __value[i] = ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->kernel[i];
                }
                return __value;
            }

            set
            {
                if (value != null)
                {
                    for (int i = 0; i < 12; i++)
                        ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->kernel[i] = value[i];
                }
            }
        }

        public global::Intel.MklDnn.MkldnnDataTypeT AccumDataType
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*) __Instance)->accum_data_type;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnPoolingDescT.__Internal*)__Instance)->accum_data_type = value;
            }
        }
    }

    /// <summary>A descriptor of a Local Response Normalization (LRN) operation.</summary>
    public unsafe partial class MkldnnLrnDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 1432)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnAlgKindT alg_kind;

            [FieldOffset(16)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal data_desc;

            [FieldOffset(712)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_data_desc;

            [FieldOffset(1408)]
            internal long local_size;

            [FieldOffset(1416)]
            internal float lrn_alpha;

            [FieldOffset(1420)]
            internal float lrn_beta;

            [FieldOffset(1424)]
            internal float lrn_k;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_lrn_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnLrnDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnLrnDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnLrnDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnLrnDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnLrnDescT __CreateInstance(global::Intel.MklDnn.MkldnnLrnDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnLrnDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnLrnDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnLrnDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnLrnDescT(global::Intel.MklDnn.MkldnnLrnDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnLrnDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnLrnDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnLrnDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnLrnDescT(global::Intel.MklDnn.MkldnnLrnDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnLrnDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnLrnDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnAlgKindT AlgKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->alg_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->alg_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DataDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->data_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->data_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDataDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->diff_data_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->diff_data_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public long LocalSize
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->local_size;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->local_size = value;
            }
        }

        public float LrnAlpha
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->lrn_alpha;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->lrn_alpha = value;
            }
        }

        public float LrnBeta
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->lrn_beta;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->lrn_beta = value;
            }
        }

        public float LrnK
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*) __Instance)->lrn_k;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnLrnDescT.__Internal*)__Instance)->lrn_k = value;
            }
        }
    }

    /// <summary>A descriptor of a Batch Normalization operation.</summary>
    public unsafe partial class MkldnnBatchNormalizationDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 3496)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal data_desc;

            [FieldOffset(704)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_data_desc;

            [FieldOffset(1400)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal data_scaleshift_desc;

            [FieldOffset(2096)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_data_scaleshift_desc;

            [FieldOffset(2792)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal stat_desc;

            [FieldOffset(3488)]
            internal float batch_norm_epsilon;

            [FieldOffset(3492)]
            internal uint flags;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_batch_normalization_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnBatchNormalizationDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnBatchNormalizationDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnBatchNormalizationDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnBatchNormalizationDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnBatchNormalizationDescT __CreateInstance(global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnBatchNormalizationDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnBatchNormalizationDescT(global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnBatchNormalizationDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnBatchNormalizationDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnBatchNormalizationDescT(global::Intel.MklDnn.MkldnnBatchNormalizationDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnBatchNormalizationDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DataDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->data_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->data_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDataDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->diff_data_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->diff_data_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DataScaleshiftDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->data_scaleshift_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->data_scaleshift_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDataScaleshiftDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->diff_data_scaleshift_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->diff_data_scaleshift_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT StatDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->stat_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->stat_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public float BatchNormEpsilon
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->batch_norm_epsilon;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->batch_norm_epsilon = value;
            }
        }

        public uint Flags
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*) __Instance)->flags;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnBatchNormalizationDescT.__Internal*)__Instance)->flags = value;
            }
        }
    }

    /// <summary>A descriptor of an inner product operation.</summary>
    public unsafe partial class MkldnnInnerProductDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 5584)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal src_desc;

            [FieldOffset(704)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_src_desc;

            [FieldOffset(1400)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal weights_desc;

            [FieldOffset(2096)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_weights_desc;

            [FieldOffset(2792)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal bias_desc;

            [FieldOffset(3488)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_bias_desc;

            [FieldOffset(4184)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal dst_desc;

            [FieldOffset(4880)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_dst_desc;

            [FieldOffset(5576)]
            internal global::Intel.MklDnn.MkldnnDataTypeT accum_data_type;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_inner_product_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnInnerProductDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnInnerProductDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnInnerProductDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnInnerProductDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnInnerProductDescT __CreateInstance(global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnInnerProductDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnInnerProductDescT(global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnInnerProductDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnInnerProductDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnInnerProductDescT(global::Intel.MklDnn.MkldnnInnerProductDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnInnerProductDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT SrcDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->src_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->src_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffSrcDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->diff_src_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->diff_src_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT WeightsDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->weights_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->weights_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffWeightsDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->diff_weights_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->diff_weights_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT BiasDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->bias_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->bias_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffBiasDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->diff_bias_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->diff_bias_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DstDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->dst_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->dst_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDstDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->diff_dst_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->diff_dst_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnDataTypeT AccumDataType
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*) __Instance)->accum_data_type;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnInnerProductDescT.__Internal*)__Instance)->accum_data_type = value;
            }
        }
    }

    /// <summary>A descriptor for an RNN operation.</summary>
    public unsafe partial class MkldnnRnnDescT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 15344)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal global::Intel.MklDnn.MkldnnPrimitiveKindT primitive_kind;

            [FieldOffset(4)]
            internal global::Intel.MklDnn.MkldnnPropKindT prop_kind;

            [FieldOffset(8)]
            internal global::Intel.MklDnn.MkldnnAlgKindT cell_kind;

            [FieldOffset(12)]
            internal global::Intel.MklDnn.MkldnnRnnDirectionT direction;

            [FieldOffset(16)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal src_layer_desc;

            [FieldOffset(712)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal src_iter_desc;

            [FieldOffset(1408)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal src_iter_c_desc;

            [FieldOffset(2104)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal weights_layer_desc;

            [FieldOffset(2800)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal weights_iter_desc;

            [FieldOffset(3496)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal bias_desc;

            [FieldOffset(4192)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal dst_layer_desc;

            [FieldOffset(4888)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal dst_iter_desc;

            [FieldOffset(5584)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal dst_iter_c_desc;

            [FieldOffset(6280)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal placeholder_desc;

            [FieldOffset(6976)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal placeholder2_desc;

            [FieldOffset(7672)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_src_layer_desc;

            [FieldOffset(8368)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_src_iter_desc;

            [FieldOffset(9064)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_src_iter_c_desc;

            [FieldOffset(9760)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_weights_layer_desc;

            [FieldOffset(10456)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_weights_iter_desc;

            [FieldOffset(11152)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_bias_desc;

            [FieldOffset(11848)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_dst_layer_desc;

            [FieldOffset(12544)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_dst_iter_desc;

            [FieldOffset(13240)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_dst_iter_c_desc;

            [FieldOffset(13936)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_placeholder_desc;

            [FieldOffset(14632)]
            internal global::Intel.MklDnn.MkldnnMemoryDescT.__Internal diff_placeholder2_desc;

            [FieldOffset(15328)]
            internal uint flags;

            [FieldOffset(15332)]
            internal global::Intel.MklDnn.MkldnnAlgKindT activation_kind;

            [FieldOffset(15336)]
            internal float alpha;

            [FieldOffset(15340)]
            internal float beta;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_rnn_desc_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnRnnDescT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnRnnDescT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnRnnDescT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnRnnDescT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnRnnDescT __CreateInstance(global::Intel.MklDnn.MkldnnRnnDescT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnRnnDescT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnRnnDescT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnRnnDescT.__Internal));
            *(global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnRnnDescT(global::Intel.MklDnn.MkldnnRnnDescT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnRnnDescT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnRnnDescT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnRnnDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnRnnDescT(global::Intel.MklDnn.MkldnnRnnDescT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnRnnDescT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnRnnDescT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::Intel.MklDnn.MkldnnPrimitiveKindT PrimitiveKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->primitive_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->primitive_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnPropKindT PropKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->prop_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->prop_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnAlgKindT CellKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->cell_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->cell_kind = value;
            }
        }

        public global::Intel.MklDnn.MkldnnRnnDirectionT Direction
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->direction;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->direction = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT SrcLayerDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->src_layer_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->src_layer_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT SrcIterDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->src_iter_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->src_iter_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT SrcIterCDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->src_iter_c_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->src_iter_c_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT WeightsLayerDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->weights_layer_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->weights_layer_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT WeightsIterDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->weights_iter_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->weights_iter_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT BiasDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->bias_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->bias_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DstLayerDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->dst_layer_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->dst_layer_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DstIterDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->dst_iter_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->dst_iter_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DstIterCDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->dst_iter_c_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->dst_iter_c_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT PlaceholderDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->placeholder_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->placeholder_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT Placeholder2Desc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->placeholder2_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->placeholder2_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffSrcLayerDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_src_layer_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_src_layer_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffSrcIterDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_src_iter_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_src_iter_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffSrcIterCDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_src_iter_c_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_src_iter_c_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffWeightsLayerDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_weights_layer_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_weights_layer_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffWeightsIterDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_weights_iter_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_weights_iter_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffBiasDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_bias_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_bias_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDstLayerDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_dst_layer_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_dst_layer_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDstIterDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_dst_iter_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_dst_iter_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffDstIterCDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_dst_iter_c_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_dst_iter_c_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffPlaceholderDesc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_placeholder_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_placeholder_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public global::Intel.MklDnn.MkldnnMemoryDescT DiffPlaceholder2Desc
        {
            get
            {
                return global::Intel.MklDnn.MkldnnMemoryDescT.__CreateInstance(new global::System.IntPtr(&((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->diff_placeholder2_desc));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->diff_placeholder2_desc = *(global::Intel.MklDnn.MkldnnMemoryDescT.__Internal*) value.__Instance;
            }
        }

        public uint Flags
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->flags;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->flags = value;
            }
        }

        public global::Intel.MklDnn.MkldnnAlgKindT ActivationKind
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->activation_kind;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->activation_kind = value;
            }
        }

        public float Alpha
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->alpha;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->alpha = value;
            }
        }

        public float Beta
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*) __Instance)->beta;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnRnnDescT.__Internal*)__Instance)->beta = value;
            }
        }
    }

    /// <summary>An auxiliary structure to specify primitive's inputs/outputs at execution</summary>
/// <remarks>
/// <para>With this API it's impossible to preserve constness of memory, so all</para>
/// <para>memories are passed w/o const qualifier. However only memories with</para>
/// <para>output semantics might be changed during the execution</para>
/// </remarks>
    public unsafe partial class MkldnnExecArgT : IDisposable
    {
        [StructLayout(LayoutKind.Explicit, Size = 16)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal int arg;

            [FieldOffset(8)]
            internal global::System.IntPtr memory;

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="??0mkldnn_exec_arg_t@@QEAA@AEBU0@@Z")]
            internal static extern global::System.IntPtr cctor(global::System.IntPtr __instance, global::System.IntPtr _0);
        }

        public global::System.IntPtr __Instance { get; protected set; }

        protected int __PointerAdjustment;
        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnExecArgT> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::Intel.MklDnn.MkldnnExecArgT>();
        protected internal void*[] __OriginalVTables;

        protected bool __ownsNativeInstance;

        internal static global::Intel.MklDnn.MkldnnExecArgT __CreateInstance(global::System.IntPtr native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnExecArgT(native.ToPointer(), skipVTables);
        }

        internal static global::Intel.MklDnn.MkldnnExecArgT __CreateInstance(global::Intel.MklDnn.MkldnnExecArgT.__Internal native, bool skipVTables = false)
        {
            return new global::Intel.MklDnn.MkldnnExecArgT(native, skipVTables);
        }

        private static void* __CopyValue(global::Intel.MklDnn.MkldnnExecArgT.__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnExecArgT.__Internal));
            *(global::Intel.MklDnn.MkldnnExecArgT.__Internal*) ret = native;
            return ret.ToPointer();
        }

        private MkldnnExecArgT(global::Intel.MklDnn.MkldnnExecArgT.__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected MkldnnExecArgT(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new global::System.IntPtr(native);
        }

        public MkldnnExecArgT()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnExecArgT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public MkldnnExecArgT(global::Intel.MklDnn.MkldnnExecArgT _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::Intel.MklDnn.MkldnnExecArgT.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::Intel.MklDnn.MkldnnExecArgT.__Internal*) __Instance) = *((global::Intel.MklDnn.MkldnnExecArgT.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true);
        }

        public virtual void Dispose(bool disposing)
        {
            if (__Instance == IntPtr.Zero)
                return;
            global::Intel.MklDnn.MkldnnExecArgT __dummy;
            NativeToManagedMap.TryRemove(__Instance, out __dummy);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public int Arg
        {
            get
            {
                return ((global::Intel.MklDnn.MkldnnExecArgT.__Internal*) __Instance)->arg;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnExecArgT.__Internal*)__Instance)->arg = value;
            }
        }

        public global::Intel.MklDnn.MkldnnMemory Memory
        {
            get
            {
                global::Intel.MklDnn.MkldnnMemory __result0;
                if (((global::Intel.MklDnn.MkldnnExecArgT.__Internal*) __Instance)->memory == IntPtr.Zero) __result0 = null;
                else if (global::Intel.MklDnn.MkldnnMemory.NativeToManagedMap.ContainsKey(((global::Intel.MklDnn.MkldnnExecArgT.__Internal*) __Instance)->memory))
                    __result0 = (global::Intel.MklDnn.MkldnnMemory) global::Intel.MklDnn.MkldnnMemory.NativeToManagedMap[((global::Intel.MklDnn.MkldnnExecArgT.__Internal*) __Instance)->memory];
                else __result0 = global::Intel.MklDnn.MkldnnMemory.__CreateInstance(((global::Intel.MklDnn.MkldnnExecArgT.__Internal*) __Instance)->memory);
                return __result0;
            }

            set
            {
                ((global::Intel.MklDnn.MkldnnExecArgT.__Internal*)__Instance)->memory = ReferenceEquals(value, null) ? global::System.IntPtr.Zero : value.__Instance;
            }
        }
    }

    public unsafe partial class mkldnn_debug
    {
        public partial struct __Internal
        {
            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_status2str")]
            internal static extern global::System.IntPtr MkldnnStatus2str(global::Intel.MklDnn.MkldnnStatusT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_dt2str")]
            internal static extern global::System.IntPtr MkldnnDt2str(global::Intel.MklDnn.MkldnnDataTypeT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_fmt_kind2str")]
            internal static extern global::System.IntPtr MkldnnFmtKind2str(global::Intel.MklDnn.MkldnnFormatKindT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_fmt_tag2str")]
            internal static extern global::System.IntPtr MkldnnFmtTag2str(global::Intel.MklDnn.MkldnnFormatTagT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_prop_kind2str")]
            internal static extern global::System.IntPtr MkldnnPropKind2str(global::Intel.MklDnn.MkldnnPropKindT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_prim_kind2str")]
            internal static extern global::System.IntPtr MkldnnPrimKind2str(global::Intel.MklDnn.MkldnnPrimitiveKindT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_alg_kind2str")]
            internal static extern global::System.IntPtr MkldnnAlgKind2str(global::Intel.MklDnn.MkldnnAlgKindT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_rnn_flags2str")]
            internal static extern global::System.IntPtr MkldnnRnnFlags2str(global::Intel.MklDnn.MkldnnRnnFlagsT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_rnn_direction2str")]
            internal static extern global::System.IntPtr MkldnnRnnDirection2str(global::Intel.MklDnn.MkldnnRnnDirectionT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_engine_kind2str")]
            internal static extern global::System.IntPtr MkldnnEngineKind2str(global::Intel.MklDnn.MkldnnEngineKindT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_scratchpad_mode2str")]
            internal static extern global::System.IntPtr MkldnnScratchpadMode2str(global::Intel.MklDnn.MkldnnScratchpadModeT v);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_md2fmt_str")]
            internal static extern int MkldnnMd2fmtStr(sbyte* fmt_str, ulong fmt_str_len, global::System.IntPtr md);

            [SuppressUnmanagedCodeSecurity]
            [DllImport("mkldnn", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
                EntryPoint="mkldnn_md2dim_str")]
            internal static extern int MkldnnMd2dimStr(sbyte* dim_str, ulong dim_str_len, global::System.IntPtr md);
        }

        public static string MkldnnStatus2str(global::Intel.MklDnn.MkldnnStatusT v)
        {
            var __ret = __Internal.MkldnnStatus2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnDt2str(global::Intel.MklDnn.MkldnnDataTypeT v)
        {
            var __ret = __Internal.MkldnnDt2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnFmtKind2str(global::Intel.MklDnn.MkldnnFormatKindT v)
        {
            var __ret = __Internal.MkldnnFmtKind2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnFmtTag2str(global::Intel.MklDnn.MkldnnFormatTagT v)
        {
            var __ret = __Internal.MkldnnFmtTag2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnPropKind2str(global::Intel.MklDnn.MkldnnPropKindT v)
        {
            var __ret = __Internal.MkldnnPropKind2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnPrimKind2str(global::Intel.MklDnn.MkldnnPrimitiveKindT v)
        {
            var __ret = __Internal.MkldnnPrimKind2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnAlgKind2str(global::Intel.MklDnn.MkldnnAlgKindT v)
        {
            var __ret = __Internal.MkldnnAlgKind2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnRnnFlags2str(global::Intel.MklDnn.MkldnnRnnFlagsT v)
        {
            var __ret = __Internal.MkldnnRnnFlags2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnRnnDirection2str(global::Intel.MklDnn.MkldnnRnnDirectionT v)
        {
            var __ret = __Internal.MkldnnRnnDirection2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnEngineKind2str(global::Intel.MklDnn.MkldnnEngineKindT v)
        {
            var __ret = __Internal.MkldnnEngineKind2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        public static string MkldnnScratchpadMode2str(global::Intel.MklDnn.MkldnnScratchpadModeT v)
        {
            var __ret = __Internal.MkldnnScratchpadMode2str(v);
            return Marshal.PtrToStringAnsi(__ret);
        }

        /// <summary>Forms a format string for a given memory descriptor.</summary>
/// <remarks>
/// <para>The format is defined as: 'dt:[p|o|0]:fmt_kind:fmt:extra'.</para>
/// <para>Here:</para>
/// <para>- dt       -- data type</para>
/// <para>- p        -- indicates there is non-trivial padding</para>
/// <para>- o        -- indicates there is non-trivial padding offset</para>
/// <para>- 0        -- indicates there is non-trivial offset0</para>
/// <para>- fmt_kind -- format kind (blocked, wino, etc...)</para>
/// <para>- fmt      -- extended format string (format_kind specific)</para>
/// <para>- extra    -- shows extra fields (underspecified)</para>
/// </remarks>
        public static int MkldnnMd2fmtStr(sbyte* fmt_str, ulong fmt_str_len, global::Intel.MklDnn.MkldnnMemoryDescT md)
        {
            var __arg2 = ReferenceEquals(md, null) ? global::System.IntPtr.Zero : md.__Instance;
            var __ret = __Internal.MkldnnMd2fmtStr(fmt_str, fmt_str_len, __arg2);
            return __ret;
        }

        /// <summary>Forms a dimension string for a given memory descriptor.</summary>
/// <remarks>The format is defined as: 'dim0xdim1x...xdimN</remarks>
        public static int MkldnnMd2dimStr(sbyte* dim_str, ulong dim_str_len, global::Intel.MklDnn.MkldnnMemoryDescT md)
        {
            var __arg2 = ReferenceEquals(md, null) ? global::System.IntPtr.Zero : md.__Instance;
            var __ret = __Internal.MkldnnMd2dimStr(dim_str, dim_str_len, __arg2);
            return __ret;
        }
    }
}
